[{"path":"https://swihart.github.io/mvpd/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 Bruce J. Swihart Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://swihart.github.io/mvpd/articles/deep_dive_kolm.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Deeper Dive: Kolmogorov Distribution, Density, Random Variates","text":"Kolmogorov distribution multivariate product distributions? Turns distribution based Kolmogorov distribution – commonly known development application goodness--fit tests – useful making elliptically contoured multivariate logistic distributions. two (equivalent) ways represent Kolmogorov distribution, sometimes called “limiting form” - means involves infinite sum. third form introduced, “splices” first two representations together:","code":""},{"path":"https://swihart.github.io/mvpd/articles/deep_dive_kolm.html","id":"cumulative-distribution-function","dir":"Articles","previous_headings":"Background","what":"Cumulative Distribution Function","title":"Deeper Dive: Kolmogorov Distribution, Density, Random Variates","text":"Representation 1: FK1(x)=1−2∑=1∞(−1)−1exp(−2i2x2)F_{K1}(x) = 1 - 2 \\sum^{\\infty}_{=1} (-1)^{-1} \\exp{\\left(-2 ^2 x^2\\right)} Representation 2: FK2(x)=2πx∑=1∞exp(−(2i−1)2π2/(8x2))F_{K2}(x) = \\frac{\\sqrt{2 \\pi}}{x} \\sum^{\\infty}_{=1} \\exp{\\left(-(2 - 1)^2 \\pi^2 / \\left( 8 x^2\\right)      \\right)} Representation 3: FK2(x)∀x∈[0,xc)F_{K2}(x)~~\\forall x \\[0,x_c) FK1(x)∀x∈[xc,∞)F_{K1}(x)~~\\forall x \\[x_c,\\infty) taking derivative respect xx, get corresponding limiting forms density:","code":""},{"path":"https://swihart.github.io/mvpd/articles/deep_dive_kolm.html","id":"density","dir":"Articles","previous_headings":"Background","what":"Density","title":"Deeper Dive: Kolmogorov Distribution, Density, Random Variates","text":"Representation 1: fK1(x)=−2∑=1∞(−1)−1(−4i2x)exp(−2i2x2)f_{K1}(x) = - 2 \\sum^{\\infty}_{=1} (-1)^{-1}  \\left(-4 ^2 x\\right)  \\exp{\\left(-2 ^2 x^2\\right)} Representation 2: fK2(x)=2π4x4∑=1∞((2i−1)2π2−4x2)exp(−(2i−1)2π2/(8x2))f_{K2}(x) = \\frac{\\sqrt{2 \\pi}}{4x^4}   \\sum^{\\infty}_{=1} \\left((2 - 1)^2 \\pi^2 - 4x^2 \\right)   \\exp{\\left(-(2 - 1)^2 \\pi^2 / \\left( 8 x^2\\right)   \\right)} Representation 3: fK2(x)∀x∈[0,xc)f_{K2}(x)~~\\forall x \\[0,x_c) fK1(x)∀x∈[xc,∞)f_{K1}(x)~~\\forall x \\[x_c,\\infty) Check expected value – π2ln2=\\sqrt{\\frac{\\pi}{2}}\\ln2 = 0.8687312…. One code, can use mpvd::dkolm: code / base R: Using mvpd::dkolm: printout shows agreement 11th digit. Next, plot densities also print values. takeaways : K1K1 representation stuggles small xx K2K2 representation struggles larger xx Yet, K2K2 representation better small xx K1K1 representation better larger xx now see motivation construction K3K3. Representation K3K3 uses K1K1 larger xx values bigger cutpoint K2K2 xx values smaller cutpoint. default value cutpoint K3cutpt = 2. pick nterms=10 demonstrate problems - practice pick number terms much higher, say 1e5, makes violations less egregious moderate values xx violations can still persist extremely small large values xx. Therefore, solely increasing nterms may solution (depending application) K1K1 K2K2. ’s mvpd uses ’’spliced” version K3K3 well default 100,000 terms.","code":"dkolm(1,rep=\"K1\") #> [1] 1.071949 dkolm(1,rep=\"K2\") #> [1] 1.071949 dkolm(1,rep=\"K3\") #> [1] 1.071949 f <- function(x,nterms=1e5){    k=1:nterms;    -2*sum( (-1)^(k-1) * -4*x*k^2 * exp(-2*k^2*x^2) ) } f_vec <- Vectorize(f, \"x\") x_f_vec <- function(x) x*f_vec(x,nterms=1e5) integrate(x_f_vec,0,Inf) #> 0.8687312 with absolute error < 1.7e-05 x_f_K1 <- function(x, nterms=1e5) x*dkolm(x,nterms,rep=\"K1\") x_f_K2 <- function(x, nterms=1e5) x*dkolm(x,nterms,rep=\"K2\") x_f_K3 <- function(x, nterms=1e5) x*dkolm(x,nterms,rep=\"K3\")  mom1_K1 <- integrate(x_f_K1, 0, Inf)[1] mom1_K2 <- integrate(x_f_K2, 0, Inf)[1] mom1_K3 <- integrate(x_f_K3, 0, Inf)[1]  print(matrix(c(mom1_K1, mom1_K2, mom1_K3, sqrt(pi/2)*log(2)),ncol=1), digits=20) #>      [,1]                   #> [1,] 0.86873116063485644744 #> [2,] 0.86873116063489197458 #> [3,] 0.8687311606348562254  #> [4,] 0.86873116063615907212"},{"path":"https://swihart.github.io/mvpd/articles/deep_dive_kolm.html","id":"plot-density","dir":"Articles","previous_headings":"Background > Density","what":"Plot density","title":"Deeper Dive: Kolmogorov Distribution, Density, Random Variates","text":"nterms=10  Since K1K1 alternating sum, number terms odd, ’ll see K1K1 produces aberrant values positive, instead negative. However K2K2 gets close 0 x=12x=12 still negative. nterms=11","code":"xdom <- c(seq(0.0,1,0.01), seq(1.1,6,.1), 8,10,12) plot(xdom,dkolm(xdom,nterms=10,rep=\"K1\"), main=\"K1 struggles with small x\", ylab=\"\", xlab=\"x\") abline(h=0,col=\"blue\") plot(xdom,dkolm(xdom,nterms=10,rep=\"K2\"), main=\"K2 struggles with large x\", ylab=\"\", xlab=\"x\") abline(h=0,col=\"blue\")  dkolm(12,rep=\"K2\",nterms=10) #> [1] -0.005592438 #> [1] -0.005592438 from rep=\"K2\"  plot(xdom,dkolm(xdom,nterms=10,rep=\"K3\"), main=\"K3: best of both worlds\", ylab=\"\", xlab=\"x\") abline(h=0,col=\"blue\") dkolm(12,rep=\"K3\",nterms=10) #> [1] 8.043785e-124 #> [1] -0.005592438 from rep=\"K2\" xdom <- c(seq(0.0,1,0.01), seq(1.1,6,.1), 8,10,12) plot(xdom,dkolm(xdom,nterms=11,rep=\"K1\"), main=\"K1 struggles with small x\", ylab=\"\", xlab=\"x\") abline(h=0,col=\"blue\") plot(xdom,dkolm(xdom,nterms=11,rep=\"K2\"), main=\"K2 struggles with large x\", ylab=\"\", xlab=\"x\") abline(h=0,col=\"blue\")  dkolm(12,rep=\"K2\",nterms=11) #> [1] -0.002983048 #> [1] -0.002983048 from rep=\"K2\"  plot(xdom,dkolm(xdom,nterms=11,rep=\"K3\"), main=\"K3: best of both worlds\", ylab=\"\", xlab=\"x\") abline(h=0,col=\"blue\")  dkolm(12,rep=\"K3\",nterms=11) #> [1] 8.043785e-124 #> [1] -0.002983048 from rep=\"K2\""},{"path":"https://swihart.github.io/mvpd/articles/deep_dive_kolm.html","id":"random-variates","dir":"Articles","previous_headings":"Background","what":"Random Variates","title":"Deeper Dive: Kolmogorov Distribution, Density, Random Variates","text":"well-known formulation random variates L(x/2) […], formulation scale mixture normal distribution become logistic distribution. Using formulation can easily derive get random variates L(x), Kolmgorov distribution. Turns just need generate many ..d. exponential(rate=2) variables, sum squared integers denominators, take square root sum.  Check expected value – π2ln2=\\sqrt{\\frac{\\pi}{2}}\\ln2 = 0.8687312…. One code, can use mpvd:rkolm:","code":"#par(mfrow=c(2,2)) y_range_rv <- c(0,1.8) x_range_rv <- c(0,4) n <- 3e4; nterms <- 2000 ##rv <- rkolm(1e4,500)  ## this is from L(x/2) rv <- 2*matrix(stats::rexp(n*nterms, rate=1), n, nterms) %*%   matrix(1/c(1:nterms)^2,nrow=nterms) range_rv <- range(rv) x<-seq(range_rv[1],range_rv[2],0.01) hist(sqrt(rv),freq=FALSE,breaks=130,       ylim=y_range_rv, xlim=x_range_rv, main=\"0.5*dkolm(x*0.5)\", xlab=\"x\") lines(x,0.5*dkolm(x*0.5), col=\"red\",lty=2, lwd=4)  ## this is from L(x) rv <- 1*matrix(stats::rexp(n*nterms, rate=2), n, nterms) %*%   matrix(1/c(1:nterms)^2,nrow=nterms) range_rv <- range(rv) x<-seq(range_rv[1],range_rv[2],0.01) hist(sqrt(rv),freq=FALSE,breaks=130,       ylim=y_range_rv, xlim=x_range_rv, main=\"dkolm(x)\", xlab=\"x\") lines(x, dkolm(x), col=\"cyan\",lty=2,lwd=4)  ## equivalently, using rkolm() ## rkolm does all the steps, including the final sqrt() hist(rkolm(n,nterms),freq=FALSE,breaks=130,       ylim=y_range_rv, xlim=x_range_rv, main=\"dkolm(x)\", xlab=\"x\") lines(x, dkolm(x), col=\"orange\",lty=2,lwd=4)   # rv <- rnorm(1e4, sd=2) # range_rv <- range(rv) # x<-seq(range_rv[1],range_rv[2],0.01) # hist(rv,freq=FALSE,breaks=100) # lines(x,0.5*dnorm(0.5*x), col=\"red\",lty=2, lwd=4) set.seed(102)  beg <- Sys.time() rkdraw <- rkolm(5e4, nterms=5e2) end <- Sys.time() end-beg #> Time difference of 0.8797574 secs  ## Expected value print(matrix(c(   mean(rkdraw),   sqrt(pi/2)*log(2)),   ncol=1),    digits=20) #>                        [,1] #> [1,] 0.86871931109979994012 #> [2,] 0.86873116063615907212  ## Variance print(matrix(c(   var(rkdraw),   pi^2/12 - (sqrt(pi/2)*log(2))^2),   ncol=1),    digits=20) #>                         [,1] #> [1,] 0.067522504088769474961 #> [2,] 0.067773203963865213950  ## 2nd moment print(matrix(c(   mean(rkdraw^2),   pi^2/12),   ncol=1),    digits=20) #>                        [,1] #> [1,] 0.82219439511639869078 #> [2,] 0.82246703342411320303"},{"path":[]},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_i.html","id":"overview-sketch","dir":"Articles","previous_headings":"Restatement of the Relations","what":"Overview Sketch","title":"(XY)^Z Part I","text":"original problem stated : X ~ U(0,1) Y ~ U(0,1) Z ~ U(0,1) (XY)^Z ~ U(0,1) first note Beta(α\\alpha, 1) generalization U(0,1). α=1\\alpha=1, Beta(1,1) U(0,1). hunch result generalize, α>0\\alpha > 0, state: X ~ Beta(α\\alpha, 1) Y ~ Beta(α\\alpha, 1) Z ~ U(0,1), (XY)^Z ~ Beta(α\\alpha, 1) can generalize distribution Z Beta(1, K-1), K number random variates multiplied. original problem, K=2, X Y multiplied raised Z. Well, K=2, Beta(1,K-1) Beta(1,1) U(0,1). leaves us : X1X_1 ~ Beta(α\\alpha, 1) X2X_2 ~ Beta(α\\alpha, 1) … XKX_K ~ Beta(α\\alpha, 1) ZZ ~ Beta(1, K-1) (X1X2…XK)Z\\left(X_1 X_2 \\dots X_K \\right)^Z ~ Beta(α\\alpha, 1) Turns another computed quantity distribution: (1X1X2…XK)Z\\left( \\frac{1}{X_1 X_2 \\dots X_K} \\right)^Z ~ Pareto(scale = 1, shape=α\\alpha) make pictures computed quantities show follow distributions bit. useful, confirmatory intuition building. building intuition, view things log-scale, changes computed quantities product raised power sum multiplied scalar. Since random variables, amounts convolution change scale (aka “scale mixtures”). one can see, challenge problem right mvpd’s alley! Going forward, may useful know X ~ Beta(α\\alpha, 1) log(X)\\log(X) ~ ReflectedExp(α\\alpha) ∑k=1Klog(Xk)\\sum_{k=1}^K  \\log(X_k) ~ ReflectedGamma(K, α\\alpha) log(1X)\\log(\\frac{1}{X}) = −log(X)-\\log(X) ~ Exp(α\\alpha) ∑k=1K−log(Xk)\\sum_{k=1}^K -\\log(X_k) ~ Gamma(K, α\\alpha) well u1,u2,u3,…uKu_1, u_2, u_3, \\dots u_K iid U(0,1) min(u1,u2,u3,…uKu_1, u_2, u_3, \\dots u_K) ~ Beta(1,K-1). ’ll make lots pictures . Quickly, ’ll state showing pictures. short, intuition, sum bunch exponentials gamma, recover original exponential distribution, sum multiplied beta. Well, ’s way ’d say coffee seminar seem cool. parts fill bit : short, intuition, sum K iid exponential random variables common rate α\\alpha gamma(K,α\\alpha). recover original exponential distribution, sum multiplied beta(1, K-1) random variable. like density argument: sum S~Gamma(K,α\\alpha) density f(x)=αKΓ(K)xK−1exp(−αx)f(x) = \\frac{\\alpha^K}{\\Gamma(K)} x^{K-1} \\exp(-\\alpha x) product ZS ~ Gamma(K, α\\alpha/Z) density f(x)=(α/Z)KΓ(K)xK−1exp(−(α/Z)x)f(x) = \\frac{(\\alpha/Z)^K}{\\Gamma(K)} x^{K-1} \\exp(-(\\alpha/Z) x) Since Z random want integrate respect distribution. puzzle becomes fzf_z integral solve exponential density f(x)=αexp(−αx)f(x) = \\alpha \\exp(-\\alpha x)? ∫fxfzdz\\int f_x f_z dz = ∫f(x)=(α/Z)KΓ(K)xK−1exp(−(α/Z)x)fzdz\\int f(x) = \\frac{(\\alpha/Z)^K}{\\Gamma(K)} x^{K-1} \\exp(-(\\alpha/Z) x) f_z dz fz(z)=(1−z)K−2B(1,K−1)f_z(z) = \\frac{(1-z)^{K-2}}{B(1,K-1)}, ∫fxfzdz\\int f_x f_z dz = ∫(α/Z)KΓ(K−1)Γ(1)xK−1exp(−(α/Z)x)(1−z)K−2dz\\int \\frac{(\\alpha/Z)^K}{\\Gamma(K-1)\\Gamma(1)} x^{K-1} \\exp(-(\\alpha/Z) x) (1-z)^{K-2} dz = xK−1Γ(K−1)∫(α/Z)Kexp(−(α/Z)x)(1−z)K−2dz\\frac{x^{K-1}}{\\Gamma(K-1)}  \\int (\\alpha/Z)^K \\exp(-(\\alpha/Z) x) (1-z)^{K-2} dz = xK−1Γ(K−1)(αexp(−αx)Γ(K−1)xK+1)\\frac{x^{K-1}}{\\Gamma(K-1)} \\left( \\alpha \\exp(-\\alpha x) \\frac{\\Gamma(K-1)}{x^{K+1}}  \\right) = αexp(−αx)◼\\alpha \\exp(-\\alpha x) ~~\\blacksquare closing, generalize X, Y iid Beta(α\\alpha, 1) (α=1\\alpha=1 U(0,1)) restate result computed quantity (XY)Z(XY)^Z. consider similar, computed quantity (1XY)Z\\left(\\frac{1}{XY} \\right)^Z well. quantity build intuition thinking distributions log-scale.","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_i.html","id":"concise-statements","dir":"Articles","previous_headings":"","what":"Concise statements","title":"(XY)^Z Part I","text":"Result 1 2 generalizes U(0,1) X, Y, (XY)^Z Beta(α\\alpha, 1). iid X,Y∼X,Y \\sim Beta(α\\alpha, 1) independent Z∼U(0,1)Z \\sim U(0,1) Result 1: implies Z(logX+logY)∼Z \\left( \\log X + \\log Y \\right) \\sim ReflectedExp(α\\alpha) Result 2: implies Z(log1X+log1Y)∼Z \\left( \\log \\frac{1}{X} + \\log \\frac{1}{Y} \\right) \\sim Exp(α\\alpha) original challenge problem special α=1\\alpha = 1 instance: X,Y,ZX,Y,Z (XY)Z∼(XY)^Z  \\sim U(0,1) (Beta(1, 1) U(0,1)). Result 1-K 2-K generalizes U(0,1) Z Beta(1, K-1). iid Xk∼X_k \\sim Beta(α\\alpha, 1), k=1,...,K,K∈1,2,...k=1,...,K, K \\{1,2,...} independent Z∼Beta(1,K−1)Z \\sim Beta(1,K-1) Result 1-K: implies Z(∑logXk)∼Z \\left( \\sum \\log X_k \\right) \\sim ReflectedExp(α\\alpha) Result 2-K: implies Z(∑log1Xk)∼Z \\left( \\sum \\log \\frac{1}{X_k} \\right) \\sim Exp(α\\alpha) original challenge problem special α=1\\alpha = 1 K=2K=2 instance: X,Y,ZX,Y,Z (XY)Z∼(XY)^Z  \\sim U(0,1) (Beta(1, 1) U(0,1)). Also note holds K=1 Beta(1,0) point mass (constant) 1 (limit).","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_i.html","id":"sanity-check-result-1","dir":"Articles","previous_headings":"Concise statements","what":"Sanity check: Result 1","title":"(XY)^Z Part I","text":"Lets number simulations plot quantities see theory action (XY)Z∼(XY)^Z  \\sim Beta(α\\alpha, 1). , draw 10,000 random variates X, Y, Z, plot density histograms draws combinations draws. (Quick note: One can increase number .Rmd file linked title changing global variable nsim.switch. kept moderate web building/loading purposes; cranking allows barplots accurately “fall line” overlaid density.) also overlay theoretical result – , density mathematical/statistical theory says quantity take – purple top histogram. First α=1\\alpha=1, special uniform instance (started !) α=4.318\\alpha=4.318 arbitrary value bigger 1 α=0.633\\alpha=0.633 arbitrary value smaller 1.","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_i.html","id":"alpha-1","dir":"Articles","previous_headings":"Concise statements > Sanity check: Result 1","what":"alpha = 1","title":"(XY)^Z Part I","text":"","code":"set.seed(1) nsims <- nsim.switch aa_x <- 1 aa_y <- 1  x <- rbeta(nsims,aa_x,1) ##runif(nsims,0,1) y <- rbeta(nsims,aa_y,1) ##runif(nsims,0,1) z <- runif(nsims,0,1)  hist((x*y)^z, breaks=50, freq=FALSE, xlim=c(0,1)) lines(               seq(0,1,0.01),                      dbeta(seq(0,1,0.01),aa_x,1),                      type=\"l\",                      lwd=overlaid.dens.lwd,                      col=\"purple\" )  hist(x, freq=FALSE, breaks=50, xlim=c(0,1)) lines(               seq(0,1,0.01),                      dbeta(seq(0,1,0.01),aa_x,1),                      type=\"l\",                      lwd=overlaid.dens.lwd,                      col=\"purple\" )  ## compare mean, variance, and 2nd moment prod <- (x*y)^z  mean(prod) #> [1] 0.5000949 var(prod) #> [1] 0.08372655 var(prod) + mean(prod)^2 #> [1] 0.3338215  mean(x) #> [1] 0.501578 var(x) #> [1] 0.0843729 var(x) + mean(x)^2 #> [1] 0.3359534"},{"path":[]},{"path":[]},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_i.html","id":"log-scale-for-intuition-building","dir":"Articles","previous_headings":"Concise statements","what":"Log-scale for intuition building","title":"(XY)^Z Part I","text":"Consider log scale, changes relation product raised power sum multiplied number. words, convolution (sum two random variables) scale mixture (multiplied random variable). visualize using 5 plots arranged 3x3 grid. left column show distributions 3 components consideration (log(X), log(Y), Z), middle column just show convolution log(X) log(Y), say log(X)+log(Y), third one show scale mixture applied convolution. line appears top histogram, ’s theoretical result, bars falling nicely along line shows agreement simulation expected theoretical result. Take look alpha=1:  Quick observations – bars fall along red density line bars fall along RefelectedGamma(2,α\\alpha) density Z(log(X)+log(Y)): “recover” “get back ” original distribution convolution, log(X), need “tighten” “gather” “concentrate” log(X)+log(Y) distribution. Multiplying random number 0 1 exactly . See values alpha:","code":""},{"path":[]},{"path":[]},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_i.html","id":"sanity-check-result-2","dir":"Articles","previous_headings":"Concise statements","what":"Sanity check: Result 2","title":"(XY)^Z Part I","text":"Now draw bunch random beta uniform random variables plot quantities see theory action (1XY)Z∼\\left(\\frac{1}{XY} \\right)^Z  \\sim Pareto(scale=1=1, shape=α= \\alpha). plot theoretical result purple top histogram. First α=1\\alpha=1, special uniform instance (started Result 1!) α=4.318\\alpha=4.318 arbitrary value bigger 1 α=0.633\\alpha=0.633 arbitrary value smaller 1.","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_i.html","id":"alpha-1-000","dir":"Articles","previous_headings":"Concise statements > Sanity check: Result 2","what":"alpha = 1.000","title":"(XY)^Z Part I","text":"","code":"set.seed(1) nsims <- nsim.switch aa_x <- 1 aa_y <- 1  x <- rbeta(nsims,aa_x,1) ##runif(nsims,0,1) y <- rbeta(nsims,aa_y,1) ##runif(nsims,0,1) z <- runif(nsims,0,1)  hist((1/x*1/y)^z, breaks=nsim.switch, freq=FALSE, xlim=c(0,15), ylim=c(0,1))  lines(               seq(0,100,0.01),                      LNPar::dpareto(seq(0,100,0.01),1,alpha=aa_x),                      type=\"l\",                      lwd=overlaid.dens.lwd,                      col=\"purple\" )  hist(1/x, freq=FALSE, breaks=6e4, xlim=c(0,15), ylim=c(0,1)) lines(               seq(0,100,0.01),                      LNPar::dpareto(seq(0,100,0.01),1,alpha=aa_x),                      type=\"l\",                      lwd=overlaid.dens.lwd,                      col=\"purple\" )  ## compare mean, variance, and 2nd moment prod <- (1/x*1/y)^z mean(prod) #> [1] 8.878238 var(prod) #> [1] 4277.258 var(prod) + mean(prod)^2 #> [1] 4356.082   mean(1/x) #> [1] 10.28434 var(1/x) #> [1] 32794.94 var(1/x) + mean(1/x)^2 #> [1] 32900.71"},{"path":[]},{"path":[]},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_i.html","id":"log-scale-for-intuition-building-1","dir":"Articles","previous_headings":"Concise statements","what":"Log-scale for intuition building","title":"(XY)^Z Part I","text":"Consider log scale, changes relation product raised power sum multiplied number. words, convolution (sum two random variables) scale mixture (multiplied random variable). visualize using 5 plots arranged 3x3 grid. left column show distributions 3 components consideration (log(X), log(Y), Z), middle column just show convolution log(X) log(Y), say log(X)+log(Y), third one show scale mixture applied convolution. Take look alpha=1:  Quick observations – log(X): Exponential(α\\alpha), log(Y) Z(log(X)+log(Y))! bars fall along Gamma(2,α\\alpha) density Z(log(X)+log(Y)): “recover” “get back ” original distribution convolution, log(X), need “tighten” “gather” “concentrate” log(X)+log(Y) distribution. Multiplying random number 0 1 exactly . See values alpha:","code":""},{"path":[]},{"path":[]},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_i.html","id":"follow-up-questions","dir":"Articles","previous_headings":"Concise statements","what":"Follow-up questions","title":"(XY)^Z Part I","text":"Follow questions means can explore . top comment response video linked intro: @JobBouwman 8 months ago Adding two exponentials double outcome. multiplying random uniform scalar 0 1 average half result. comment addition video helped inspire document. comment particular inspired two questions mine. Q: “1/2 average” just “1/2 time variation”? Let’s see resultant Z(log(1/X)+log(1/Y)) distribution look like replaced z<-runif(nsims, 0, 1) z <- rep(1/2, nsims) code. see “concentrates” much doesn’t recover distribution log(1/X) – bars go well red density line exponential:  Q: Ok, Z random. can 1/2 average bounds bigger 0,1 ? Let’s see resultant Z(log(1/X)+log(1/Y)) distribution look like replaced z<-runif(nsims, 0, 1) z<-runif(nsims, -1, 2) code. mean Z 1/2. However, Z bounded 0 1. Hypothesis: even though Z “1/2 average” fails recover distribution log(1/X) Z values bigger 1 fail “tighten” distribution. Compounding problem Z values 0 (negative values) flip/reflect values across y-axis. See :","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_i.html","id":"bonus-what-about-3-exponentials","dir":"Articles","previous_headings":"","what":"Bonus: What about 3 exponentials?","title":"(XY)^Z Part I","text":"already stated Results 1-K 2-K generalized things summing K exponentials. However, let’s build intuition pretending results just tried add 3rd variable procedure point. Let’s see resultant Z(log(1/X)+log(1/Y)+log(1/)) distribution look like, X,Y,iid beta(0.633,1) independent Z iid U(0,1)  looks like need tightening Z. Let’s tinker. Instead multiplying 1/2 average, perhaps need multiply 1/3 average? Let’s leave Z uniform, positive values smaller 1 average 1/3. Let’s replace z<-runif(nsims, 0, 1) z<-runif(nsims, 0, 2/3) code:  fun, modification (shortening range uniform) quite seem “recover” distribution log(1/X). seems needed Z values smaller fill part density near 0. ’s another way get Z “1/3 average”. , draw two uniforms, V ~ uniform(0,1) W ~ uniform(0,1) let Z=min(V,W) (insight shown Dr. Mihai Nica’s follow-video. ). Note, letting Z ~ beta(1,3-1). 3 bolded, number exponentials summed. gives us way generalize K exponentials summed.  nailed ! Let’s try summing 10 exponentials. means need Z “1/10 average”. , draw 9 uniforms let Z minimum 9 uniforms. letting Z ~ beta(1,10-1). 10 bolded, number exponentials ’re summing, generalizes positive integer. mindful x-axis y-axis limits – every plot!  –>   simulations results common α\\alpha. consider case unequal α\\alpha case part II topic.","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_i.html","id":"miscellany-notes-to-self-stubs-for-future-ideas","dir":"Articles","previous_headings":"Bonus: What about 3 exponentials?","what":"Miscellany / Notes to self / Stubs for future ideas","title":"(XY)^Z Part I","text":"Proof -ln(X) Exponential transformation beta relevant =0, b=1? Keep back pocket generalizing Uniform…U(-1,1) Looking inductive form, may provide insight Z may “recovering” distribution sum 2 exponentials.","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_ii.html","id":"two-ways-","dir":"Articles","previous_headings":"","what":"Two ways.","title":"(XY)^Z Part II","text":"wanted allow different rates, two ways go . One generalize computed quantity Result 1-K 2-K. “seems obvious” given results part . , raise variable product rate distribution basically makes Exp(1) variables log scale. approach keep computed quantity see can handle different rates solely investigating distribution Z Result 1 2 (don’t try general K case). look following sections.","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_ii.html","id":"way-1-generalize-the-computed-quantities","dir":"Articles","previous_headings":"","what":"Way 1: Generalize The Computed Quantities","title":"(XY)^Z Part II","text":"X1X_1 ~ Beta(α1\\alpha_1, 1) X2X_2 ~ Beta(α2\\alpha_2, 1) … XKX_K ~ Beta(αK\\alpha_K, 1) ZZ ~ Beta(1, K-1) (X1α1X2α2…XKαK)Z\\left(X_1^{\\alpha_1} X_2^{\\alpha_2} \\dots X_K^{\\alpha_K} \\right)^Z ~ Beta(1, 1) Turns another computed quantity distribution: (1X1α1X2α2…XKαK)Z\\left( \\frac{1}{X_1^{\\alpha_1} X_2^{\\alpha_2} \\dots X_K^{\\alpha_K}} \\right)^Z ~ Pareto(scale = 1, shape=1) Let’s try summing 10 exponentials different rates… look new computed quantity. means need Z “1/10 average”. , draw 9 uniforms let Z minimum 9 uniforms. letting Z ~ beta(1,10-1). 10 bolded, number exponentials ’re summing, generalizes positive integer. mindful x-axis y-axis limits – every plot!  change computed quantity kept without α\\alphas part ? ’s topic next session.","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_ii.html","id":"way-2-keep-the-generalized-quantity-investigate-z","dir":"Articles","previous_headings":"","what":"Way 2: Keep the Generalized Quantity – Investigate Z","title":"(XY)^Z Part II","text":"part considered cases alpha X Y multiplying (log(1/X)+log(1/Y)) Z allows one recover original distribution log(1/X) (equivalently, log(1/Y)). However, αx≠αy\\alpha_x \\neq \\alpha_y, multiplying (log(1/X)+log(1/Y)) uniform recover distribution either log(1/X) log(1/Y) – distribution “-” two distributions – Exponential alpha αx\\alpha_x αy\\alpha_y. consider “unequal alpha” bonus case .","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_ii.html","id":"what-is-the-sum-in-the-unequal-rate-case","dir":"Articles","previous_headings":"Way 2: Keep the Generalized Quantity – Investigate Z","what":"What is the sum in the unequal rate case?","title":"(XY)^Z Part II","text":"Firstly, one may want consult Wikipedia. Wikipedia Sum Two Independent Exponential Random Variables , setup, one distribution recover since αx≠αy\\alpha_x \\neq \\alpha_y, trying different distributions ZZ leads different blends X,Y distributions quantity Z(log(1/X)+log(1/Y)).","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_ii.html","id":"z-distributed-as-u01","dir":"Articles","previous_headings":"Way 2: Keep the Generalized Quantity – Investigate Z","what":"Z distributed as U(0,1)","title":"(XY)^Z Part II","text":"Z∼Z \\sim U(0,1) fw(w)=−mn(Γ(0,mw)−Γ(0,nw))m−nf_w(w) = - \\frac{mn \\left( \\Gamma(0,mw) - \\Gamma(0,nw)\\right)}{ m-n } W=Z(log1X+log1Y)W = Z \\left( \\log \\frac{1}{X} + \\log \\frac{1}{Y} \\right), m=αx\\alpha_x, n=αy\\alpha_y Γ(.,.)\\Gamma(.,.) incomplete Gamma function.  computed quantity exponential, one can see concentration convolution kind “-” two component distributions.","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_ii.html","id":"z-distributed-as-inverse-gammaalpha-beta","dir":"Articles","previous_headings":"Way 2: Keep the Generalized Quantity – Investigate Z","what":"Z distributed as Inverse-Gamma(alpha, beta)","title":"(XY)^Z Part II","text":"Z∼Z \\sim Inverse-Gamma(αz\\alpha_z, βz\\beta_z) gold density fw(w)=mnn−mβzαzΓ(αz+1)Γ(αz)(1(mw+βz)αz+1−1(nw+βz)αz+1)f_w(w) = \\frac{mn}{ n-m }\\frac{\\beta_z^{\\alpha_z}\\Gamma(\\alpha_z + 1)}{ \\Gamma(\\alpha_z) } \\left( \\frac{1}{ \\left(mw+\\beta_z\\right)^{\\alpha_z +1}}-\\frac{1}{ \\left(nw+\\beta_z\\right)^{\\alpha_z +1}} \\right) W=Z(log1X+log1Y)W = Z \\left( \\log \\frac{1}{X} + \\log \\frac{1}{Y} \\right), m=αx\\alpha_x, n=αy\\alpha_y.  computed quantity exponential, one can see concentration convolution kind “-” two component distributions.","code":""},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_ii.html","id":"z-distributed-as-pareto","dir":"Articles","previous_headings":"Way 2: Keep the Generalized Quantity – Investigate Z","what":"Z distributed as Pareto","title":"(XY)^Z Part II","text":"Z∼Z \\sim Pareto(xm=1x_m=1,αm=1\\alpha_m=1) (1/Z ~ U(0,1)) magenta density: fw(w)=n2(1−exp−mw(1+mw))−m2(1−exp−nw(1+nw))mn(n−m)w2f_w(w) = \\frac{n^2 (1-\\exp^{-mw}(1+mw)) - m^2 (1-\\exp^{-nw}(1+nw))}{ mn(n-m)w^2 } W=Z(log1X+log1Y)W = Z \\left( \\log \\frac{1}{X} + \\log \\frac{1}{Y} \\right), m=αx\\alpha_x, n=αy\\alpha_y.  opposite “concentration” – bleeding ? Multiplying convolution random number bigger 1 disperses .","code":""},{"path":[]},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_iii.html","id":"beta-beta-beta","dir":"Articles","previous_headings":"","what":"Beta, Beta, Beta","title":"(XY)^Z Part III","text":"Part , kept Z U(0,1). initially swung fences, investigating generalizing original problem X,Y,Z uniform X,Y,Z beta got tantalizing results quite bring fruition. stub code ’ll write later. Browser tabs useful search: Math SE post 2012. product two betas moment matching techinque (applied product betas) using mathematica (check files) lead mathstatica reviewed /Rubi led reading 2F1()","code":"nsims <- 1e7 aa <- 8#2#1#8.5 bb <- 8#2#1#8.5 x <- rbeta(nsims, aa, bb) y <- rbeta(nsims, aa, bb) z <- rbeta(nsims, 1, 2-1)  cor(x  ,y  ) #> [1] -0.0002956492 cor(x^z,y^z) ## bc z is random #> [1] 0.7346134 cor(x^19, y^19) #> [1] 0.0006771847  xytothez <- (x*y)^z   par(mfrow=c(1,2)) hist(xytothez, freq=FALSE, breaks=50) mean(xytothez) #> [1] 0.5357581 var(xytothez) #> [1] 0.05108758 var(xytothez) + mean(xytothez)^2 #> [1] 0.3381244  hist(x, freq=FALSE, breaks=50) mean(x) #> [1] 0.5000299 var(x) #> [1] 0.01470367 var(x) + mean(x)^2 #> [1] 0.2647336  moment_integrand <- function(x, k, a, b){      #beta(a + x*k, b) / beta(a,b) * dbeta(x, a, b)      beta(a + x*k, b) / beta(a,b) *    beta(a + x*k, b) / beta(a,b) *                       dbeta(x, a, b)       }  mom2 <- as.numeric(   integrate(moment_integrand,             lower=0,             upper=1,             k=2, a=aa, b=bb)[1]) mom2 #> [1] 0.2642006 #var(x^z) + mean(x^z)^2 var(xytothez) + mean(xytothez)^2 #> [1] 0.3381244 beta(aa + 2, bb) / beta(aa,bb) #> [1] 0.2647059   mom1 <- as.numeric(   integrate(moment_integrand,             lower=0,             upper=1,             k=1, a=aa, b=bb)[1]) mom1 #> [1] 0.4997182 #mean(x^z) mean(xytothez) #> [1] 0.5357581 beta(aa + 1, bb) / beta(aa,bb) #> [1] 0.5   ## effort into getting standardized axes for the quantities involved  s.xlim <- range(c(log(x),                       log(y),                       z,                       log(x*y),                       z*log(x*y) ) ) #c(-10,0)#c(-4,2)  s.ylim <- c(0, max(dbeta(seq(s.xlim[1],s.xlim[2],0.01), aa, bb))) s.ylim #> [1] 0.000000 3.142034 s.xlim #> [1] -4.219205  1.000000  dlogbeta<-function(x,a,b) exp(a*x) * (1-exp(x))^(b-1) / beta(a,b)  par(mfcol=c(3,3)) hist(log(x), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim) lines(seq(s.xlim[1], s.xlim[2],0.01 ),       dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),                aa,                bb),       col=\"red\" )  hist(log(y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim) lines(seq(s.xlim[1], s.xlim[2],0.01 ),       dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),                aa,                bb),       col=\"red\" )  hist(    z , freq=FALSE, breaks=50, ylim=s.ylim, xlim=c(0,1))     plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab=\"\",ylab=\"\") hist(log(x)+log(y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim) plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab=\"\",ylab=\"\")  plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab=\"\",ylab=\"\") hist(z*(log(x)+log(y)), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim) # lines(seq(s.xlim[1], s.xlim[2],0.01 ), #       dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ), #                aa, #                bb), #       col=\"red\" # )  plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab=\"\",ylab=\"\") mean(   log(x)        )  #> [1] -0.7252979 digamma(aa) - digamma(aa+bb) #> [1] -0.7253719 mean(z*(log(x)+log(y))) #> [1] -0.7249533  var (   log(x)        )  #> [1] 0.06860578 trigamma(aa) - trigamma(aa+bb) #> [1] 0.06864323 var (z*(log(x)+log(y)) ) #> [1] 0.2210332   ## attempts at new relations: ## attempts at new relations: ## attempts at new relations:  con <- 1.0055 var (z^con * con * (log(x)+log(y))) #> [1] 0.2236243 mean (z^con * con * (log(x)+log(y))) #> [1] -0.7269401  con2 <- 0.0325 var (z*(log(x)+log(y) - con2 )) #> [1] 0.228978 mean(z*(log(x)+log(y) - con2 )) #> [1] -0.7411953  var (z*(log(x)+log(y)+ (log(x)*log(y))  ) ) #> [1] 0.07624856"},{"path":"https://swihart.github.io/mvpd/articles/xy_to_the_z_part_iii.html","id":"normal-approximation","dir":"Articles","previous_headings":"","what":"Normal Approximation","title":"(XY)^Z Part III","text":"get result generalizing betas, interesting note normal approximation betas","code":"nsims <- 1e6 ## https://en.wikipedia.org/wiki/Beta_distribution#Normal_approximation_to_the_Beta_distribution aa<-bb<-5.5 mu <- 0.5 sig <- (1/(4*(2*aa+1))) x <- rnorm(nsims, mu, sig) y <- rnorm(nsims, mu, sig) z <- rnorm(nsims, mu, sig)  par(mfrow=c(1,2)) hist((x*y)^z, freq=FALSE, breaks=50) mean((x*y)^z) #> [1] 0.4999955 var((x*y)^z) #> [1] 0.0004262521 hist(rnorm(nsims, mu,sig), freq=FALSE, breaks=50) mean(rnorm(nsims, mu,sig)) #> [1] 0.5000197 var(rnorm(nsims, mu,sig)) #> [1] 0.0004339315"},{"path":"https://swihart.github.io/mvpd/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Bruce Swihart. Author, maintainer.","code":""},{"path":"https://swihart.github.io/mvpd/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Swihart B (2025). mvpd: Multivariate Product Distributions Elliptically Contoured Distributions. R package version 0.0.5, https://github.com/swihart/mvpd.","code":"@Manual{,   title = {mvpd: Multivariate Product Distributions for Elliptically Contoured Distributions},   author = {Bruce Swihart},   year = {2025},   note = {R package version 0.0.5},   url = {https://github.com/swihart/mvpd}, }"},{"path":"https://swihart.github.io/mvpd/index.html","id":"mvpd-an-r-package-for-multivariate-product-distributions","dir":"","previous_headings":"","what":"Multivariate Product Distributions for Elliptically Contoured Distributions","title":"Multivariate Product Distributions for Elliptically Contoured Distributions","text":"[dpr]mvss: multivariate subgaussian stable distributions [pr]mvlogis: multivariate logistic distributions goal mvpd use product distribution theory allow numerical calculations specific scale mixtures multivariate normal distribution. multivariate subgaussian stable distribution product square root univariate positive stable distribution multivariate normal distribution (see Nolan (2013)).","code":""},{"path":"https://swihart.github.io/mvpd/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Multivariate Product Distributions for Elliptically Contoured Distributions","text":"Generate 1000 draws random bivariate subgaussian stable distribution alpha=1.71 plot.","code":"library(mvpd) set.seed(2) ## basic example code biv <- rmvss(n=1e3, alpha=1.71, Q=matrix(c(10,7.5,7.5,10),2)) head(biv) #>             [,1]      [,2] #> [1,]  3.17465324  4.122869 #> [2,] -3.26707008 -1.366920 #> [3,] -5.82800100  1.831774 #> [4,] -2.02463359 -3.749701 #> [5,]  0.01294963  3.042960 #> [6,]  1.73029594  3.812420 plot(biv); abline(h=0,v=0)"},{"path":"https://swihart.github.io/mvpd/reference/adaptIntegrate_inf_limPD.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptive multivariate integration over hypercubes (admitting infinite limits) — adaptIntegrate_inf_limPD","title":"Adaptive multivariate integration over hypercubes (admitting infinite limits) — adaptIntegrate_inf_limPD","text":"function performs adaptive multidimensional integration (cubature) (possibly) vector-valued integrands hypercubes. wrapper cubature:::adaptIntegrate, transforming (-)Inf appropriately described cubature's help page (http://ab-initio.mit.edu/wiki/index.php/Cubature#Infinite_intervals).","code":""},{"path":"https://swihart.github.io/mvpd/reference/adaptIntegrate_inf_limPD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptive multivariate integration over hypercubes (admitting infinite limits) — adaptIntegrate_inf_limPD","text":"","code":"adaptIntegrate_inf_limPD(   f,   lowerLimit,   upperLimit,   ...,   tol.ai = 1e-05,   fDim.ai = 1,   maxEval.ai = 0,   absError.ai = 0,   doChecking.ai = FALSE )"},{"path":"https://swihart.github.io/mvpd/reference/adaptIntegrate_inf_limPD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adaptive multivariate integration over hypercubes (admitting infinite limits) — adaptIntegrate_inf_limPD","text":"f function (integrand) integrated lowerLimit lower limit integration, vector hypercubes upperLimit upper limit integration, vector hypercubes ... arguments passed function f tol.ai maximum tolerance, default 1e-5. fDim.ai dimension integrand, default 1, bears relation dimension hypercube maxEval.ai maximum number function evaluations needed, default 0 implying limit absError.ai maximum absolute error tolerated doChecking.ai flag thorough checking inputs C routines. FALSE value results approximately 9 percent speed gain experiments. mileage course vary. Default value FALSE.","code":""},{"path":"https://swihart.github.io/mvpd/reference/adaptIntegrate_inf_limPD.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adaptive multivariate integration over hypercubes (admitting infinite limits) — adaptIntegrate_inf_limPD","text":"","code":"## integrate Cauchy Density from -Inf to Inf adaptIntegrate_inf_limPD(function(x) 1/pi * 1/(1+x^2), -Inf, Inf) #> $integral #> [1] 1 #>  #> $error #> [1] 1.901365e-06 #>  #> $functionEvaluations #> [1] 45 #>  #> $returnCode #> [1] 0 #>  adaptIntegrate_inf_limPD(function(x, scale) 1/(pi*scale) * 1/(1+(x/scale)^2), -Inf, Inf, scale=4) #> $integral #> [1] 1 #>  #> $error #> [1] 2.705388e-06 #>  #> $functionEvaluations #> [1] 165 #>  #> $returnCode #> [1] 0 #>  ## integrate Cauchy Density from -Inf to -3 adaptIntegrate_inf_limPD(function(x) 1/pi * 1/(1+x^2), -Inf, -3)$int #> [1] 0.1024164 stats::pcauchy(-3) #> [1] 0.1024164 adaptIntegrate_inf_limPD(function(x, scale) 1/(pi*scale) * 1/(1+(x/scale)^2), -Inf, -3, scale=4)$int #> [1] 0.2951672 stats::pcauchy(-3, scale=4) #> [1] 0.2951672"},{"path":"https://swihart.github.io/mvpd/reference/dkolm.html","id":null,"dir":"Reference","previous_headings":"","what":"Density for the Kolmogorov Distribution — dkolm","title":"Density for the Kolmogorov Distribution — dkolm","text":"Density Kolmogorov Distribution","code":""},{"path":"https://swihart.github.io/mvpd/reference/dkolm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density for the Kolmogorov Distribution — dkolm","text":"","code":"dkolm(x, nterms = 500, rep = \"K3\", K3cutpt = 2)"},{"path":"https://swihart.github.io/mvpd/reference/dkolm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density for the Kolmogorov Distribution — dkolm","text":"x domain value. nterms number terms limiting form's sum. , changing infinity top summation big K. rep representation.  See article webpage. Default 'K3'. K3cutpt cutpoint rep='K3'. Seee article webpage.","code":""},{"path":"https://swihart.github.io/mvpd/reference/dkolm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density for the Kolmogorov Distribution — dkolm","text":"value density specified x","code":""},{"path":"https://swihart.github.io/mvpd/reference/dkolm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density for the Kolmogorov Distribution — dkolm","text":"","code":"## see https://swihart.github.io/mvpd/articles/deep_dive_kolm.html dkolm(1) #> [1] 1.071949"},{"path":"https://swihart.github.io/mvpd/reference/dmvss.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate Subgaussian Stable Density — dmvss","title":"Multivariate Subgaussian Stable Density — dmvss","text":"Computes density function multivariate subgaussian stable distribution arbitrary alpha, shape matrices, location vectors. See Nolan (2013).","code":""},{"path":"https://swihart.github.io/mvpd/reference/dmvss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate Subgaussian Stable Density — dmvss","text":"","code":"dmvss(   x,   alpha = 1,   Q = NULL,   delta = rep(0, d),   outermost.int = c(\"stats::integrate\", \"cubature::adaptIntegrate\")[1],   spherical = FALSE,   subdivisions.si = 100L,   rel.tol.si = .Machine$double.eps^0.25,   abs.tol.si = rel.tol.si,   stop.on.error.si = TRUE,   tol.ai = 1e-05,   fDim.ai = 1,   maxEval.ai = 0,   absError.ai = 0,   doChecking.ai = FALSE,   which.stable = c(\"libstable4u\", \"stabledist\")[1] )"},{"path":"https://swihart.github.io/mvpd/reference/dmvss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multivariate Subgaussian Stable Density — dmvss","text":"x vector quantiles. alpha default 1 (Cauchy). Must 0<alpha<2 Q Shape matrix.  See Nolan (2013). delta location vector outermost.int select integration function use outermost integral.  Default \"stats::integrate\" one can specify following options .si suffix.  diagonal Q, one can also specify \"cubature::adaptIntegrate\" use .ai suffix options (currently bug non-diagnoal Q). spherical default FALSE.  true, use spherical transformation. Results identical spherical = FALSE may faster. subdivisions.si maximum number subintervals. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. rel.tol.si relative accuracy requested. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. abs.tol.si absolute accuracy requested. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. stop..error.si logical. true (default) error stops function. false errors give result warning message component. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. tol.ai maximum tolerance, default 1e-5. suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. fDim.ai dimension integrand, default 1, bears relation dimension hypercube suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. maxEval.ai maximum number function evaluations needed, default 0 implying limit suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. absError.ai maximum absolute error tolerated suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. doChecking.ai flag thorough checking inputs C routines. FALSE value results approximately 9 percent speed gain experiments. mileage course vary. Default value FALSE. suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. .stable defaults \"libstable4u\", option \"stabledist\".  Indicates package provide univariate stable distribution production distribution form univariate stable multivariate normal.","code":""},{"path":"https://swihart.github.io/mvpd/reference/dmvss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multivariate Subgaussian Stable Density — dmvss","text":"object returned depends selected outermost.int.  case default, stats::integrate, value list class \"integrate\" components: value final estimate integral. abs.error estimate modulus absolute error. subdivisions number subintervals produced subdivision process. message \"OK\" character string giving error message. call matched call. Note: reported abs.error likely -estimate integrate assumes integrand without error, case application.","code":""},{"path":"https://swihart.github.io/mvpd/reference/dmvss.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multivariate Subgaussian Stable Density — dmvss","text":"Nolan, John P. \"Multivariate elliptically contoured stable distributions: theory estimation.\" Computational Statistics 28.5 (2013): 2067-2089.","code":""},{"path":"https://swihart.github.io/mvpd/reference/dmvss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multivariate Subgaussian Stable Density — dmvss","text":"","code":"## print(\"mvsubgaussPD (d=2, alpha=1.71):\") Q <- matrix(c(10,7.5,7.5,10),2) mvpd::dmvss(x=c(0,1), alpha=1.71, Q=Q) #> 0.01211828 with absolute error < 5.8e-05  ## more accuracy = longer runtime mvpd::dmvss(x=c(0,1),alpha=1.71, Q=Q, abs.tol=1e-8) #> 0.01211828 with absolute error < 5.7e-07  Q <- matrix(c(10,7.5,7.5,7.5,10,7.5,7.5,7.5,10),3) ## print(\"mvsubgausPD (d=3, alpha=1.71):\") mvpd::dmvss(x=c(0,1,2), alpha=1.71, Q=Q) #> 0.001602922 with absolute error < 4.4e-05 mvpd::dmvss(x=c(0,1,2), alpha=1.71, Q=Q, spherical=TRUE) #> 0.001602922 with absolute error < 4.4e-05  ## How `delta` works: same as centering X <- c(1,1,1) Q <- matrix(c(10,7.5,7.5,7.5,10,7.5,7.5,7.5,10),3) D <- c(0.75, 0.65, -0.35) mvpd::dmvss(X-D, alpha=1.71, Q=Q) #> 0.001940025 with absolute error < 6e-05 mvpd::dmvss(X  , alpha=1.71, Q=Q, delta=D) #> 0.001940025 with absolute error < 6e-05"},{"path":"https://swihart.github.io/mvpd/reference/dmvss_mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate Subgaussian Stable Density for matrix inputs — dmvss_mat","title":"Multivariate Subgaussian Stable Density for matrix inputs — dmvss_mat","text":"Computes density function multivariate subgaussian stable distribution arbitrary alpha, shape matrices, location vectors. See Nolan (2013).","code":""},{"path":"https://swihart.github.io/mvpd/reference/dmvss_mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate Subgaussian Stable Density for matrix inputs — dmvss_mat","text":"","code":"dmvss_mat(   x,   alpha = 1,   Q = NULL,   delta = rep(0, d),   outermost.int = c(\"stats::integrate\", \"cubature::adaptIntegrate\",     \"cubature::hcubature\")[2],   spherical = FALSE,   subdivisions.si = 100L,   rel.tol.si = .Machine$double.eps^0.25,   abs.tol.si = rel.tol.si,   stop.on.error.si = TRUE,   tol.ai = 1e-05,   fDim.ai = NULL,   maxEval.ai = 0,   absError.ai = 0,   doChecking.ai = FALSE,   which.stable = c(\"libstable4u\", \"stabledist\")[1] )"},{"path":"https://swihart.github.io/mvpd/reference/dmvss_mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multivariate Subgaussian Stable Density for matrix inputs — dmvss_mat","text":"x nxd matrix n variates d-dimension alpha default 1 (Cauchy). Must 0<alpha<2 Q Shape matrix.  See Nolan (2013). delta location vector outermost.int select integration function use outermost integral.  Default \"stats::integrate\" one can specify following options .si suffix.  diagonal Q, one can also specify \"cubature::adaptIntegrate\" use .ai suffix options (currently bug non-diagnoal Q). spherical default FALSE.  true, use spherical transformation. Results identical spherical = FALSE may faster. subdivisions.si maximum number subintervals. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. rel.tol.si relative accuracy requested. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. abs.tol.si absolute accuracy requested. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. stop..error.si logical. true (default) error stops function. false errors give result warning message component. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. tol.ai maximum tolerance, default 1e-5. suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. fDim.ai dimension integrand, default 1, bears relation dimension hypercube suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. maxEval.ai maximum number function evaluations needed, default 0 implying limit suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. absError.ai maximum absolute error tolerated suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. doChecking.ai flag thorough checking inputs C routines. FALSE value results approximately 9 percent speed gain experiments. mileage course vary. Default value FALSE. suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. .stable defaults \"libstable4u\", option \"stabledist\".  Indicates package provide univariate stable distribution production distribution form univariate stable multivariate normal.","code":""},{"path":"https://swihart.github.io/mvpd/reference/dmvss_mat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multivariate Subgaussian Stable Density for matrix inputs — dmvss_mat","text":"object returned depends selected outermost.int.  case default, stats::integrate, value list class \"integrate\" components: value final estimate integral. abs.error estimate modulus absolute error. subdivisions number subintervals produced subdivision process. message \"OK\" character string giving error message. call matched call. Note: reported abs.error likely -estimate integrate assumes integrand without error, case application.","code":""},{"path":"https://swihart.github.io/mvpd/reference/dmvss_mat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multivariate Subgaussian Stable Density for matrix inputs — dmvss_mat","text":"Nolan, John P. \"Multivariate elliptically contoured stable distributions: theory estimation.\" Computational Statistics 28.5 (2013): 2067-2089.","code":""},{"path":"https://swihart.github.io/mvpd/reference/dmvss_mat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multivariate Subgaussian Stable Density for matrix inputs — dmvss_mat","text":"","code":"## print(\"mvsubgaussPD (d=2, alpha=1.71):\") Q <- matrix(c(10,7.5,7.5,10),2) mvpd::dmvss(x=c(0,1), alpha=1.71, Q=Q) #> 0.01211828 with absolute error < 5.8e-05  ## more accuracy = longer runtime mvpd::dmvss(x=c(0,1),alpha=1.71, Q=Q, abs.tol=1e-8) #> 0.01211828 with absolute error < 5.7e-07  Q <- matrix(c(10,7.5,7.5,7.5,10,7.5,7.5,7.5,10),3) ## print(\"mvsubgausPD (d=3, alpha=1.71):\") mvpd::dmvss(x=c(0,1,2), alpha=1.71, Q=Q) #> 0.001602922 with absolute error < 4.4e-05 mvpd::dmvss(x=c(0,1,2), alpha=1.71, Q=Q, spherical=TRUE) #> 0.001602922 with absolute error < 4.4e-05  ## How `delta` works: same as centering X <- c(1,1,1) Q <- matrix(c(10,7.5,7.5,7.5,10,7.5,7.5,7.5,10),3) D <- c(0.75, 0.65, -0.35) mvpd::dmvss(X-D, alpha=1.71, Q=Q) #> 0.001940025 with absolute error < 6e-05 mvpd::dmvss(X  , alpha=1.71, Q=Q, delta=D) #> 0.001940025 with absolute error < 6e-05"},{"path":"https://swihart.github.io/mvpd/reference/dmvt_mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate t-Distribution Density for matrix inputs — dmvt_mat","title":"Multivariate t-Distribution Density for matrix inputs — dmvt_mat","text":"Computes density function multivariate subgaussian stable distribution arbitrary degrees freedom, shape matrices, location vectors. See Swihart Nolan (2022).","code":""},{"path":"https://swihart.github.io/mvpd/reference/dmvt_mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate t-Distribution Density for matrix inputs — dmvt_mat","text":"","code":"dmvt_mat(   x,   df = 1,   Q = NULL,   delta = rep(0, d),   outermost.int = c(\"stats::integrate\", \"cubature::adaptIntegrate\",     \"cubature::hcubature\")[2],   spherical = FALSE,   subdivisions.si = 100L,   rel.tol.si = .Machine$double.eps^0.25,   abs.tol.si = rel.tol.si,   stop.on.error.si = TRUE,   tol.ai = 1e-05,   fDim.ai = NULL,   maxEval.ai = 0,   absError.ai = 0,   doChecking.ai = FALSE )"},{"path":"https://swihart.github.io/mvpd/reference/dmvt_mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multivariate t-Distribution Density for matrix inputs — dmvt_mat","text":"x nxd matrix n variates d-dimension df default 1 (Cauchy). df t-dist, real number df>0. Can non-integer. Q Shape matrix.  See Nolan (2013). delta location vector outermost.int select integration function use outermost integral.  Default \"stats::integrate\" one can specify following options .si suffix.  diagonal Q, one can also specify \"cubature::adaptIntegrate\" use .ai suffix options (currently bug non-diagnoal Q). spherical default FALSE.  true, use spherical transformation. Results identical spherical = FALSE may faster. subdivisions.si maximum number subintervals. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. rel.tol.si relative accuracy requested. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. abs.tol.si absolute accuracy requested. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. stop..error.si logical. true (default) error stops function. false errors give result warning message component. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. tol.ai maximum tolerance, default 1e-5. suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. fDim.ai dimension integrand, default 1, bears relation dimension hypercube suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. maxEval.ai maximum number function evaluations needed, default 0 implying limit suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. absError.ai maximum absolute error tolerated suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. doChecking.ai flag thorough checking inputs C routines. FALSE value results approximately 9 percent speed gain experiments. mileage course vary. Default value FALSE. suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation.","code":""},{"path":"https://swihart.github.io/mvpd/reference/dmvt_mat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multivariate t-Distribution Density for matrix inputs — dmvt_mat","text":"object returned depends selected outermost.int.  case default, stats::integrate, value list class \"integrate\" components: value final estimate integral. abs.error estimate modulus absolute error. subdivisions number subintervals produced subdivision process. message \"OK\" character string giving error message. call matched call. Note: reported abs.error likely -estimate integrate assumes integrand without error, case application.","code":""},{"path":"https://swihart.github.io/mvpd/reference/dmvt_mat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multivariate t-Distribution Density for matrix inputs — dmvt_mat","text":"Swihart & Nolan, \"R Journal: Multivariate Subgaussian Stable Distributions R\", R Journal, 2022","code":""},{"path":"https://swihart.github.io/mvpd/reference/dmvt_mat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multivariate t-Distribution Density for matrix inputs — dmvt_mat","text":"","code":"x <- c(1.23, 4.56) mu <- 1:2 Sigma <- matrix(c(4, 2, 2, 3), ncol=2) df01 <- mvtnorm::dmvt(x, delta = mu, sigma = Sigma, df =  1, log=FALSE) # default log = TRUE! df10 <- mvtnorm::dmvt(x, delta = mu, sigma = Sigma, df = 10, log=FALSE) # default log = TRUE! df30 <- mvtnorm::dmvt(x, delta = mu, sigma = Sigma, df = 30, log=FALSE) # default log = TRUE! df01 #> [1] 0.007027824 df10 #> [1] 0.01164573 df30 #> [1] 0.01223266   dmvt_mat(   matrix(x,ncol=2),   df = 1,   Q = Sigma,   delta=mu)$int #> [1] 0.007027824   dmvt_mat(   matrix(x,ncol=2),   df = 10,   Q = Sigma,   delta=mu)$int #> [1] 0.01164573   dmvt_mat(   matrix(x,ncol=2),   df = 30,   Q = Sigma,   delta=mu)$int #> [1] 0.01223266  ## Q: can we do non-integer degrees of freedom? ## A: yes for both mvpd::dmvt_mat and mvtnorm::dmvt  df1.5 <- mvtnorm::dmvt(x, delta = mu, sigma = Sigma, df =  1.5, log=FALSE) # default log = TRUE! df1.5 #> [1] 0.008221199  dmvt_mat(   matrix(x,ncol=2),   df = 1.5,   Q = Sigma,   delta=mu)$int #> [1] 0.008221199   ## Q: can we do <1 degrees of freedom but >0? ## A: yes for both mvpd::dmvt_mat and mvtnorm::dmvt  df0.5 <- mvtnorm::dmvt(x, delta = mu, sigma = Sigma, df =  0.5, log=FALSE) # default log = TRUE! df0.5 #> [1] 0.004938052  dmvt_mat(   matrix(x,ncol=2),   df = 0.5,   Q = Sigma,   delta=mu)$int #> [1] 0.004938052  df0.0001 <- mvtnorm::dmvt(x, delta = mu, sigma = Sigma, df =  0.0001,                            log=FALSE) # default log = TRUE! df0.0001 #> [1] 1.873233e-06  dmvt_mat(   matrix(x,ncol=2),   df = 0.0001,   Q = Sigma,   delta=mu)$int #> [1] 1.873233e-06    ## Q: can we do ==0 degrees of freedom? ## A: No for both mvpd::dmvt_mat and mvtnorm::dmvt  ## this just becomes normal, as per the manual for mvtnorm::dmvt df0.0 <- mvtnorm::dmvt(x, delta = mu, sigma = Sigma, df =  0, log=FALSE) # default log = TRUE! df0.0 #> [1] 0.01254144  dmvt_mat(   matrix(x,ncol=2),   df = 0,   Q = Sigma,   delta=mu)$int  #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> [1] NaN"},{"path":"https://swihart.github.io/mvpd/reference/fit_mvss.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Multivariate Subgaussian Distribution — fit_mvss","title":"Fit a Multivariate Subgaussian Distribution — fit_mvss","text":"Estimates parameters (namely, alpha, shape matrix Q, location vector) multivariate subgaussian distribution input matrix X.","code":""},{"path":"https://swihart.github.io/mvpd/reference/fit_mvss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a Multivariate Subgaussian Distribution — fit_mvss","text":"","code":"fit_mvss(x)"},{"path":"https://swihart.github.io/mvpd/reference/fit_mvss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a Multivariate Subgaussian Distribution — fit_mvss","text":"x matrix parameters d-dimensional multivariate subgaussian distribution estimated.  number columns d.","code":""},{"path":"https://swihart.github.io/mvpd/reference/fit_mvss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a Multivariate Subgaussian Distribution — fit_mvss","text":"list parameters column-wise univariate fits multivariate alpha shape matrix estimates (univ_deltas mult_deltas): univ_alphas - alphas column-wise univariate fits univ_betas  - betas  column-wise univariate fits univ_gammas - gammas column-wise univariate fits univ_deltas - deltas column-wise univariate fits mult_alpha  - mean(univ_alphas); equivalently multivariate alpha estimate mult_Q_raw  - multivariate shape matrix estimate (applying nearPD()) mult_Q_posdef   - nearest positive definite multivariate shape matrix estimate, nearPD(mult_Q_raw)","code":""},{"path":"https://swihart.github.io/mvpd/reference/fit_mvss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a Multivariate Subgaussian Distribution — fit_mvss","text":"Using protocols outlined Nolan (2013), function uses libstable4u's univariate fit functions component.","code":""},{"path":"https://swihart.github.io/mvpd/reference/fit_mvss.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit a Multivariate Subgaussian Distribution — fit_mvss","text":"Nolan JP (2013), Multivariate elliptically contoured stable distributions: theory estimation. Comput Stat (2013) 28:2067–2089 DOI 10.1007/s00180-013-0396-7","code":""},{"path":[]},{"path":"https://swihart.github.io/mvpd/reference/fit_mvss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a Multivariate Subgaussian Distribution — fit_mvss","text":"","code":"# \\donttest{ ## create a 4x4 shape matrix symMat S <- matrix(rnorm(4*4, mean=2, sd=4),4);  symMat <- as.matrix(Matrix::nearPD(0.5 * (S + t(S)))$mat) symMat #>            [,1]      [,2]       [,3]       [,4] #> [1,]  1.4405616  2.581618 -0.5364308  0.4824483 #> [2,]  2.5816179  6.898871 -2.7719604 -0.5159260 #> [3,] -0.5364308 -2.771960  1.6424608  0.9203432 #> [4,]  0.4824483 -0.515926  0.9203432  1.0002679 ## generate 10,000 r.v.'s from 4-dimensional mvss X <- mvpd::rmvss(1e4, alpha=1.5, Q=symMat, delta=c(1,2,3,4)) ## use fit_mvss to recover the parameters, compare to symMat fmv <- mvpd::fit_mvss(X) fmv #> $univ_alphas #> [1] 1.513308 1.537871 1.536045 1.518953 #>  #> $univ_betas #> [1]  0.001161657  0.008100327 -0.025793228  0.004121532 #>  #> $univ_gammas #> [1] 1.2004493 2.6457106 1.3009471 0.9991121 #>  #> $univ_deltas #> [1] 0.9553778 1.9263515 2.9844314 3.9725634 #>  #> $mult_alpha #> [1] 1.526544 #>  #> $mult_Q_raw #>            [,1]       [,2]       [,3]       [,4] #> [1,]  1.4410786  2.6832637 -0.5723522  0.4562007 #> [2,]  2.6832637  6.9997844 -2.8527823 -0.5335773 #> [3,] -0.5723522 -2.8527823  1.6924633  0.9081656 #> [4,]  0.4562007 -0.5335773  0.9081656  0.9982249 #>  #> $mult_Q_posdef #>            [,1]       [,2]       [,3]       [,4] #> [1,]  1.4673593  2.6667974 -0.5869613  0.4490156 #> [2,]  2.6667974  7.0101013 -2.8436289 -0.5290755 #> [3,] -0.5869613 -2.8436289  1.7005843  0.9121597 #> [4,]  0.4490156 -0.5290755  0.9121597  1.0001893 #>  symMat #>            [,1]      [,2]       [,3]       [,4] #> [1,]  1.4405616  2.581618 -0.5364308  0.4824483 #> [2,]  2.5816179  6.898871 -2.7719604 -0.5159260 #> [3,] -0.5364308 -2.771960  1.6424608  0.9203432 #> [4,]  0.4824483 -0.515926  0.9203432  1.0002679 ## then use the fitted parameters to calculate a probability: mvpd::pmvss(lower=rep(0,4),             upper=rep(5,4),             alpha=fmv$mult_alpha,             Q=fmv$mult_Q_posdef,             delta=fmv$univ_deltas,             maxpts.pmvnorm = 25000*10) #> 0.3194962 with absolute error < 9.9e-06 # }"},{"path":"https://swihart.github.io/mvpd/reference/mvpd.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate Product Distributions — mvpd","title":"Multivariate Product Distributions — mvpd","text":"purpose package offer density, probability, random variate generating (abbreviated [d/p/r], respectively) functions multivariate distributions can represented product distribution. Specifically, package primarily focus product multivariate normal distribution univariate random variable. product distributions called Scale Mixtures Multivariate Normal Distributions, particular choices univariate random variable distribution resultant product distribution may family interest.  instance, square-root positive stable random variable multiplied multivariate normal distribution multivariate subgaussian stable distribution. Product distribution theory applied implementing computation.","code":""},{"path":"https://swihart.github.io/mvpd/reference/mvpd.html","id":"multivariate-subgaussian-stable-distributions","dir":"Reference","previous_headings":"","what":"Multivariate subgaussian stable distributions","title":"Multivariate Product Distributions — mvpd","text":"dmvss – multivariate subgaussian stable distribution density pmvss – multivariate subgaussian stable distribution probabilities rmvss – multivariate subgaussian stable distribution random variates pmvss_mc – Monte Carlo version probabilities, using rmvss fit_mvss – Fit multivariate subgaussian stable distribution (e.g. estimate parameters given data)","code":""},{"path":[]},{"path":"https://swihart.github.io/mvpd/reference/mvpd.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multivariate Product Distributions — mvpd","text":"Maintainer: Bruce Swihart bruce.swihart@gmail.com (ORCID)","code":""},{"path":"https://swihart.github.io/mvpd/reference/pmvss.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate Subgaussian Stable Distribution — pmvss","title":"Multivariate Subgaussian Stable Distribution — pmvss","text":"Computes probabilities multivariate subgaussian stable distribution arbitrary limits, alpha, shape matrices, location vectors. See Nolan (2013).","code":""},{"path":"https://swihart.github.io/mvpd/reference/pmvss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate Subgaussian Stable Distribution — pmvss","text":"","code":"pmvss(   lower = rep(-Inf, d),   upper = rep(Inf, d),   alpha = 1,   Q = NULL,   delta = rep(0, d),   maxpts.pmvnorm = 25000,   abseps.pmvnorm = 0.001,   outermost.int = c(\"stats::integrate\", \"cubature::adaptIntegrate\")[1],   subdivisions.si = 100L,   rel.tol.si = .Machine$double.eps^0.25,   abs.tol.si = rel.tol.si,   stop.on.error.si = TRUE,   tol.ai = 1e-05,   fDim.ai = 1,   maxEval.ai = 0,   absError.ai = 0,   doChecking.ai = FALSE,   which.stable = c(\"libstable4u\", \"stabledist\")[1] )"},{"path":"https://swihart.github.io/mvpd/reference/pmvss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multivariate Subgaussian Stable Distribution — pmvss","text":"lower vector lower limits length n. upper vector upper limits length n. alpha default 1 (Cauchy). Must 0<alpha<2 Q Shape matrix.  See Nolan (2013). delta location vector. maxpts.pmvnorm Defaults 25000.  Passed F_G = pmvnorm() integrand outermost integral. abseps.pmvnorm Defaults 1e-3. Passed F_G = pmvnorm() integrand outermost integral. outermost.int select integration function use outermost integral.  Default \"stats::integrate\" one can specify following options .si suffix.  diagonal Q, one can also specify \"cubature::adaptIntegrate\" use .ai suffix options (currently bug non-diagonal Q). subdivisions.si maximum number subintervals. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. rel.tol.si relative accuracy requested. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. abs.tol.si absolute accuracy requested. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. stop..error.si logical. true (default) error stops function. false errors give result warning message component. suffix .si indicates stats::integrate() option outermost semi-infinite integral product distribution formulation. tol.ai maximum tolerance, default 1e-5. suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. fDim.ai dimension integrand, default 1, bears relation dimension hypercube suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. maxEval.ai maximum number function evaluations needed, default 0 implying limit suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. absError.ai maximum absolute error tolerated suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. doChecking.ai flag thorough checking inputs C routines. FALSE value results approximately 9 percent speed gain experiments. mileage course vary. Default value FALSE. suffix .ai indicates cubature::adaptIntegrate type option outermost semi-infinite integral product distribution formulation. .stable defaults \"libstable4u\", option \"stabledist\".  Indicates package provide univariate stable distribution production distribution form univariate stable multivariate normal.","code":""},{"path":"https://swihart.github.io/mvpd/reference/pmvss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multivariate Subgaussian Stable Distribution — pmvss","text":"object returned depends selected outermost.int.  case default, stats::integrate, value list class \"integrate\" components: value final estimate integral. abs.error estimate modulus absolute error. subdivisions number subintervals produced subdivision process. message \"OK\" character string giving error message. call matched call. Note: reported abs.error likely -estimate integrate assumes integrand without error, case application.","code":""},{"path":"https://swihart.github.io/mvpd/reference/pmvss.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multivariate Subgaussian Stable Distribution — pmvss","text":"Nolan JP (2013), Multivariate elliptically contoured stable distributions: theory estimation. Comput Stat (2013) 28:2067–2089 DOI 10.1007/s00180-013-0396-7","code":""},{"path":"https://swihart.github.io/mvpd/reference/pmvss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multivariate Subgaussian Stable Distribution — pmvss","text":"","code":"## bivariate U <- c(1,1) L <- -U Q <- matrix(c(10,7.5,7.5,10),2) mvpd::pmvss(L, U, alpha=1.71, Q=Q) #> 0.04973221 with absolute error < 4.2e-05  ## trivariate U <- c(1,1,1) L <- -U Q <- matrix(c(10,7.5,7.5,7.5,10,7.5,7.5,7.5,10),3) mvpd::pmvss(L, U, alpha=1.71, Q=Q) #> 0.01591192 with absolute error < 1.7e-05  ## How `delta` works: same as centering U <- c(1,1,1) L <- -U Q <- matrix(c(10,7.5,7.5,7.5,10,7.5,7.5,7.5,10),3) D <- c(0.75, 0.65, -0.35) mvpd::pmvss(L-D, U-D, alpha=1.71, Q=Q) #> 0.01446922 with absolute error < 0.00011 mvpd::pmvss(L  , U  , alpha=1.71, Q=Q, delta=D) #> 0.01446928 with absolute error < 0.00011"},{"path":"https://swihart.github.io/mvpd/reference/pmvss_mc.html","id":null,"dir":"Reference","previous_headings":"","what":"Monte Carlo Multivariate Subgaussian Stable Distribution — pmvss_mc","title":"Monte Carlo Multivariate Subgaussian Stable Distribution — pmvss_mc","text":"Computes probabilities multivariate subgaussian stable distribution arbitrary limits, alpha, shape matrices, location vectors via Monte Carlo (thus suffix _mc).","code":""},{"path":"https://swihart.github.io/mvpd/reference/pmvss_mc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Monte Carlo Multivariate Subgaussian Stable Distribution — pmvss_mc","text":"","code":"pmvss_mc(   lower = rep(-Inf, d),   upper = rep(Inf, d),   alpha = 1,   Q = NULL,   delta = rep(0, d),   which.stable = c(\"libstable4u\", \"stabledist\")[1],   n = NULL )"},{"path":"https://swihart.github.io/mvpd/reference/pmvss_mc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Monte Carlo Multivariate Subgaussian Stable Distribution — pmvss_mc","text":"lower vector lower limits length n. upper vector upper limits length n. alpha default 1 (Cauchy). Must 0<alpha<2 Q Shape matrix.  See Nolan (2013). delta location vector. .stable defaults \"libstable4u\", option \"stabledist\".  Indicates package provide univariate stable distribution production distribution form univariate stable multivariate normal. n number random vectors drawn Monte Carlo calculation.","code":""},{"path":"https://swihart.github.io/mvpd/reference/pmvss_mc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Monte Carlo Multivariate Subgaussian Stable Distribution — pmvss_mc","text":"number 0 1, estimated probability via Monte Carlo","code":""},{"path":"https://swihart.github.io/mvpd/reference/pmvss_mc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Monte Carlo Multivariate Subgaussian Stable Distribution — pmvss_mc","text":"Nolan JP (2013), Multivariate elliptically contoured stable distributions: theory estimation. Comput Stat (2013) 28:2067–2089 DOI 10.1007/s00180-013-0396-7","code":""},{"path":"https://swihart.github.io/mvpd/reference/pmvss_mc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Monte Carlo Multivariate Subgaussian Stable Distribution — pmvss_mc","text":"","code":"## print(\"mvpd (d=2, alpha=1.71):\") U <- c(1,1) L <- -U Q <- matrix(c(10,7.5,7.5,10),2) mvpd::pmvss_mc(L, U, alpha=1.71, Q=Q, n=1e3) #> [1] 0.053 mvpd::pmvss   (L, U, alpha=1.71, Q=Q) #> 0.04973221 with absolute error < 4.2e-05  ## more accuracy = longer runtime mvpd::pmvss_mc(L, U, alpha=1.71, Q=Q, n=1e4) #> [1] 0.048  U <- c(1,1,1) L <- -U Q <- matrix(c(10,7.5,7.5,7.5,10,7.5,7.5,7.5,10),3) ## print(\"mvpd: (d=3, alpha=1.71):\") mvpd::pmvss_mc(L, U, alpha=1.71, Q=Q, n=1e3) #> [1] 0.02"},{"path":"https://swihart.github.io/mvpd/reference/rkolm.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Variates for the Kolmogorov Distribution — rkolm","title":"Random Variates for the Kolmogorov Distribution — rkolm","text":"Random Variates Kolmogorov Distribution","code":""},{"path":"https://swihart.github.io/mvpd/reference/rkolm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Variates for the Kolmogorov Distribution — rkolm","text":"","code":"rkolm(n, nterms = 500)"},{"path":"https://swihart.github.io/mvpd/reference/rkolm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Variates for the Kolmogorov Distribution — rkolm","text":"n number random variate simulate nterms number terms limiting sum. , turning infinity Big K top summation.","code":""},{"path":"https://swihart.github.io/mvpd/reference/rkolm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Variates for the Kolmogorov Distribution — rkolm","text":"n random variates","code":""},{"path":"https://swihart.github.io/mvpd/reference/rkolm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Variates for the Kolmogorov Distribution — rkolm","text":"","code":"## see https://swihart.github.io/mvpd/articles/deep_dive_kolm.html rkolm(10) #>            [,1] #>  [1,] 1.0478984 #>  [2,] 0.9128781 #>  [3,] 1.5500009 #>  [4,] 0.7625867 #>  [5,] 1.0481328 #>  [6,] 1.1179143 #>  [7,] 0.7362769 #>  [8,] 0.6785036 #>  [9,] 0.8433051 #> [10,] 0.6017721"},{"path":"https://swihart.github.io/mvpd/reference/rmvlogis.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate Logistic Random Variables — rmvlogis","title":"Multivariate Logistic Random Variables — rmvlogis","text":"Computes random vectors multivariate symmetric logistic distribution arbitrary correlation matrices using asymptotic Kolmogorov distribution – see references.","code":""},{"path":"https://swihart.github.io/mvpd/reference/rmvlogis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate Logistic Random Variables — rmvlogis","text":"","code":"rmvlogis(n, Q = NULL, delta = rep(0, d), BIG = 500)"},{"path":"https://swihart.github.io/mvpd/reference/rmvlogis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multivariate Logistic Random Variables — rmvlogis","text":"n number observations Q semi-positive definite delta location vector. BIG number exponential add asymptotic Kolomogrov","code":""},{"path":"https://swihart.github.io/mvpd/reference/rmvlogis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multivariate Logistic Random Variables — rmvlogis","text":"Scale Mixtures Normal Distributions Author(s): D. F. Andrews C. L. Mallows Source: Journal Royal Statistical Society. Series B (Methodological), Vol. 36, . 1 (1974), pp. 99-102 Published : Wiley Royal Statistical Society Stable URL: http://www.jstor.org/stable/2984774","code":""},{"path":"https://swihart.github.io/mvpd/reference/rmvlogis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multivariate Logistic Random Variables — rmvlogis","text":"","code":"rmvlogis(10, Q=diag(5)) #>             [,1]       [,2]       [,3]       [,4]        [,5] #>  [1,] -1.4554436 -0.5413883 -0.8667427 -0.5031270  1.36947506 #>  [2,] -0.8491013 -0.8416934  1.8264470  0.6601506  0.98888253 #>  [3,] -2.8792461  1.0411447  1.8077202  1.6215116 -0.07824789 #>  [4,]  0.8069226 -0.3484485 -0.4003437  1.2489126 -0.60357591 #>  [5,] -1.5304412 -1.9614416  0.6800465 -2.5021227  2.64421762 #>  [6,]  0.0658620  0.1420186  1.4567006  0.3147913  0.60365273 #>  [7,]  0.1771488 -0.2844730 -1.3069375 -1.0245978  0.42505409 #>  [8,] -0.9856645 -0.7346512 -0.3280713  0.3037126  2.69082351 #>  [9,]  1.9138452 -0.8799090 -2.9995169 -2.9453641  2.68784938 #> [10,]  2.0868364 -0.5954600  0.6351749 -0.6499376 -1.92336192  if (FALSE) { # \\dontrun{ QMAT <- matrix(c(1,0,0,1),nrow=2) draw_NNMD  <- NonNorMvtDist::rmvlogis(2e3, parm1=rep(0,2), parm2=rep(1,2)) draw_mvpd  <-          mvpd::rmvlogis(2e3,     Q=QMAT)  mean(draw_NNMD[,1]   < -1 & draw_NNMD[,2]   < 3) mean(draw_mvpd[,1] < -1 & draw_mvpd[,2] < 3)  plogis(-1) mean(draw_NNMD[,1] < -1) mean(draw_mvpd[,1] < -1)  plogis(3) mean(draw_NNMD[,2] < 3) mean(draw_mvpd[,2] < 3)   rangex <- range(c(draw_mvpd[,1],draw_NNMD[,1])) rangey <- range(c(draw_mvpd[,2],draw_NNMD[,2]))  par(mfrow=c(3,2), pty=\"s\", mai=c(.5,.1,.1,.1)) plot(draw_NNMD, xlim=rangex, ylim=rangey); abline(h=0,v=0) plot(draw_mvpd   , xlim=rangex, ylim=rangey); abline(h=0,v=0)  hist(draw_NNMD[,1]  , breaks = 100,  xlim=rangex, probability=TRUE, ylim=c(0,.40)) curve(dlogis(x), add=TRUE, col=\"blue\",lwd=2) hist(draw_mvpd[,1], breaks = 100,  xlim=rangex, probability=TRUE, ylim=c(0,.40)) curve(dlogis(x), add=TRUE, col=\"blue\",lwd=2) hist(draw_NNMD[,2]  , breaks = 100,  xlim=rangex, probability=TRUE, ylim=c(0,.40)) curve(dlogis(x), add=TRUE, col=\"blue\",lwd=2) hist(draw_mvpd[,2], breaks = 100,  xlim=rangex, probability=TRUE, ylim=c(0,.40)) curve(dlogis(x), add=TRUE, col=\"blue\",lwd=2) } # }"},{"path":"https://swihart.github.io/mvpd/reference/rmvss.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate Subgaussian Stable Random Variates — rmvss","title":"Multivariate Subgaussian Stable Random Variates — rmvss","text":"Computes random vectors multivariate subgaussian stable distribution arbitrary alpha, shape matrices, location vectors. See Nolan (2013).","code":""},{"path":"https://swihart.github.io/mvpd/reference/rmvss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate Subgaussian Stable Random Variates — rmvss","text":"","code":"rmvss(   n,   alpha = 1,   Q = NULL,   delta = rep(0, d),   which.stable = c(\"libstable4u\", \"stabledist\")[1] )"},{"path":"https://swihart.github.io/mvpd/reference/rmvss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multivariate Subgaussian Stable Random Variates — rmvss","text":"n number observations alpha default 1 (Cauchy). Must 0<alpha<2 Q Shape matrix.  See Nolan (2013). delta location vector. .stable defaults \"libstable4u\", option \"stabledist\".  Indicates package provide univariate stable distribution production distribution form univariate stable multivariate normal.","code":""},{"path":"https://swihart.github.io/mvpd/reference/rmvss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multivariate Subgaussian Stable Random Variates — rmvss","text":"Returns n d matrix containing multivariate subgaussian stable random variates d=nrow(Q).","code":""},{"path":"https://swihart.github.io/mvpd/reference/rmvss.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multivariate Subgaussian Stable Random Variates — rmvss","text":"Nolan JP (2013), Multivariate elliptically contoured stable distributions: theory estimation. Comput Stat (2013) 28:2067–2089 DOI 10.1007/s00180-013-0396-7","code":""},{"path":"https://swihart.github.io/mvpd/reference/rmvss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multivariate Subgaussian Stable Random Variates — rmvss","text":"","code":"## generate 10 random variates of a bivariate mvss rmvss(n=10, alpha=1.71, Q=matrix(c(10,7.5,7.5,10),2)) #>              [,1]       [,2] #>  [1,]  -3.1547271  -2.103857 #>  [2,]  -3.7144064  -5.604734 #>  [3,]   5.2082938   2.551250 #>  [4,]  -0.2412486   3.810356 #>  [5,]   1.7277478   1.988887 #>  [6,] -23.5193885 -40.459124 #>  [7,]   4.8197852   7.089041 #>  [8,]   0.2690873   1.446094 #>  [9,]  -2.1926593  -7.589429 #> [10,]   7.2049296   5.295507  ## generate 10 random variates of a trivariate mvss Q <- matrix(c(10,7.5,7.5,7.5,10,7.5,7.5,7.5,10),3) rmvss(n=10, alpha=1.71, Q=Q) #>              [,1]         [,2]       [,3] #>  [1,]  -1.1757654  -2.43884743  4.5784581 #>  [2,]   3.2302965  -0.29315919 -1.3906679 #>  [3,]   1.5894881  -1.22109764 -0.3356316 #>  [4,]   0.9949992  -0.06168804 -4.0382708 #>  [5,]  -3.6108905 -11.65373754 -4.5608165 #>  [6,]  -1.8763509  -2.69880449 -4.4783599 #>  [7,]   3.6767780   7.68304748  3.1228319 #>  [8,] -12.3291686  -5.18658197 -7.2320985 #>  [9,]  11.1562491   5.19857597  2.3980446 #> [10,]   3.2788009   4.33402699  1.8478028"},{"path":"https://swihart.github.io/mvpd/news/index.html","id":"mvpd-005","dir":"Changelog","previous_headings":"","what":"mvpd 0.0.5","title":"mvpd 0.0.5","text":"add dmvss_mat(). function may faster dmvss() can handle matrix inputs add dmvt_mat(). developmental multivariate t distribution add [pr]mvlogis add [dr]kolm","code":""},{"path":"https://swihart.github.io/mvpd/news/index.html","id":"mvpd-004","dir":"Changelog","previous_headings":"","what":"mvpd 0.0.4","title":"mvpd 0.0.4","text":"CRAN release: 2023-09-03 fixed roxygen token changed reverse depends libstableR libstable4u","code":""},{"path":"https://swihart.github.io/mvpd/news/index.html","id":"mvpd-003","dir":"Changelog","previous_headings":"","what":"mvpd 0.0.3","title":"mvpd 0.0.3","text":"CRAN release: 2022-06-20 Improved help pages fit_mvss rmvss Added tests","code":""},{"path":"https://swihart.github.io/mvpd/news/index.html","id":"mvpd-002","dir":"Changelog","previous_headings":"","what":"mvpd 0.0.2","title":"mvpd 0.0.2","text":"CRAN release: 2022-03-30 Added multivariate subgaussian stable capabilities","code":""},{"path":"https://swihart.github.io/mvpd/news/index.html","id":"mvpd-001","dir":"Changelog","previous_headings":"","what":"mvpd 0.0.1","title":"mvpd 0.0.1","text":"CRAN release: 2022-03-23 Added NEWS.md file track changes package.","code":""}]
