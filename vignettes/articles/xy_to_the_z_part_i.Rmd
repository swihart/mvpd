---
title: "(XY)^Z Part I"
author: Bruce J. Swihart
date: 2025-05-16
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include=FALSE}
library(mvpd)
```

___ 

**IN PROGRESS**

---

I'm about 8 months late to the party, but a challenge problem from 3blue1brown
caught my attention, as well as a call for intuitive approaches to explaining the result.

> Here's the challenge mode for all you math whizzes. Sample three numbers x, y, z uniformly at random in [0, 1], and compute (xy)^z. What distribution describes this result?
>
> Answer: It's uniform!
>
> I know how to prove it, but haven't yet found the "aha" style explanation where it feels expected or visualizable. If any of you have one, please send it my way and I'll strongly consider making a video on it.
>
> -- Grant Sanderson of 3blue1brown, 2024-09-10


The result and good explanations of the result have been around for a while, as shown in this [Math SE post from 2012](https://math.stackexchange.com/q/261783/180716).  

This [response video by 
Dr Mihai Nica](https://www.youtube.com/watch?v=qNXBwiAsvZM&t=277s) has an explanation that is similar to the one on this page and connects it to Poisson processes and some other statistical results.  I focus more on visualizing the distributions and thinking of the result in terms of convolution and scale mixture, which should be no surprise given these are commonly used in the underlying theory of `mvpd`.  I also generalize the result, showing that the original problem is a specific instance of the more general result.


## Restatement of the Result

For iid $X,Y \sim$ Beta($\alpha$, 1) and independent $Z \sim U(0,1)$

  * $(XY)^Z  \sim$ Beta($\alpha$, 1)
    * Which implies $Z \left( \log X + \log Y \right) \sim$ ReflectedExp($\alpha$)
  * $\left(\frac{1}{XY} \right)^Z  \sim$ Pareto($x_m=1$, $\alpha_m = \alpha$)
    * Which implies $Z \left( \log \frac{1}{X} + \log \frac{1}{Y} \right) \sim$ Exp($\alpha$)


Special instance: For $\alpha = 1$, $X,Y,Z$ and $(XY)^Z  \sim$ U(0,1) (because Beta(1, 1) is U(0,1)).

  [Proof of -ln(X) being an Exponential](https://math.stackexchange.com/a/3173387/180716)


## Bonus: $\alpha_x \neq \alpha_y$

  * [Wikipedia Sum of Two Independent Exponential Random Variables](https://en.wikipedia.org/wiki/Exponential_distribution#Sum_of_two_independent_exponential_random_variables)
  

There's no *one* distribution to recover since  $\alpha_x \neq \alpha_y$, so trying different distributions for $Z$ leads to different blends of  the X,Y distributions:

### $Z \sim$ U(0,1)

  * mathematica says I need incomplete gamma. luckily [vincent goulet made one for R](https://search.r-project.org/CRAN/refmans/expint/html/gammainc.html).
  * page 80 green notebook
  
### $Z \sim$ Gamma

  * page 82 green notebook
  
### $Z \sim$ Pareto  

  * TBD. don't have R code yet.  see page 81 green notebook
  
  
#### Miscellany

  * [Is this transformation of beta relevant for a=0, b=1?](https://math.stackexchange.com/a/4039033/180716)
  
  * [Keep in back pocket for generalizing Uniform...U(-1,1)](https://stats.stackexchange.com/a/461337/35034)

