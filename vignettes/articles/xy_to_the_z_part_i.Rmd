---
title: "(XY)^Z Part I"
author: Bruce J. Swihart
date: 2025-05-16
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include=FALSE}
library(mvpd)
```

___ 

**IN PROGRESS**

---

I'm about 8 months late to the party, but a challenge problem from 3blue1brown
caught my attention, as well as a call for intuitive approaches to explaining the result.

> Here's the challenge mode for all you math whizzes. Sample three numbers x, y, z uniformly at random in [0, 1], and compute (xy)^z. What distribution describes this result?
>
> Answer: It's uniform!
>
> I know how to prove it, but haven't yet found the "aha" style explanation where it feels expected or visualizable. If any of you have one, please send it my way and I'll strongly consider making a video on it.
>
> -- Grant Sanderson of 3blue1brown, 2024-09-10


The result and good explanations of the result have been around for a while, as shown in this [Math SE post from 2012](https://math.stackexchange.com/q/261783/180716).  

This [response video by 
Dr Mihai Nica](https://www.youtube.com/watch?v=qNXBwiAsvZM&t=277s) has an explanation that is similar to the one on this page and connects it to Poisson processes and some other statistical results.  I focus more on visualizing the distributions and thinking of the result in terms of convolution and scale mixture, which should be no surprise given these are commonly used in the underlying theory of `mvpd`.  I also generalize the result, showing that the original problem is a specific instance of the more general result.


## Restatement of the Result

For iid $X,Y \sim$ Beta($\alpha$, 1) and independent $Z \sim U(0,1)$

**Result 1**:

  * $(XY)^Z  \sim$ Beta($\alpha$, 1)
    * Which implies $Z \left( \log X + \log Y \right) \sim$ ReflectedExp($\alpha$)

**Result 2**:    

  * $\left(\frac{1}{XY} \right)^Z  \sim$ Pareto($x_m=1$, $\alpha_m = \alpha$)
    * Which implies $Z \left( \log \frac{1}{X} + \log \frac{1}{Y} \right) \sim$ Exp($\alpha$)


Special instance: For $\alpha = 1$, $X,Y,Z$ and $(XY)^Z  \sim$ U(0,1) (because Beta(1, 1) is U(0,1)).



###  Sanity check: Result 1

Lets do a number of simulations and then plot the quantities to see the theory in action for $(XY)^Z  \sim$ Beta($\alpha$, 1).  We'll plot the theoretical result in purple on top of the histogram.  First for $\alpha=1$, the special uniform instance (because that is what started it all!) and $\alpha=4.318$ as an arbitrary value bigger than 1 and $\alpha=0.633$ as an arbitrary value smaller than 1.


#### alpha = 1

```{r, fig.show="hold", out.width="50%"}
set.seed(1)
nsims <- 1e4
aa_x <- 1
aa_y <- 1

x <- rbeta(nsims,aa_x,1) ##runif(nsims,0,1)
y <- rbeta(nsims,aa_y,1) ##runif(nsims,0,1)
z <- runif(nsims,0,1)


  
hist((x*y)^z, breaks=50, freq=FALSE, xlim=c(0,1))

lines(               seq(0,1,0.01),
                     dbeta(seq(0,1,0.01),aa_x,1),
                     type="l",
                     col="purple"
)

hist(x, freq=FALSE, breaks=50, xlim=c(0,1))
lines(               seq(0,1,0.01),
                     dbeta(seq(0,1,0.01),aa_x,1),
                     type="l",
                     col="purple"
)

## compare mean, variance, and 2nd moment
prod <- (x*y)^z
mean(prod)
var(prod)
var(prod) + mean(prod)^2


mean(x)
var(x)
var(x) + mean(x)^2



```

#### alpha = 4.318

```{r, fig.show="hold", out.width="50%", echo=FALSE, results='hide'}
set.seed(1)
nsims <- 1e4
aa_x <- 4.318
aa_y <- 4.318

x <- rbeta(nsims,aa_x,1) ##runif(nsims,0,1)
y <- rbeta(nsims,aa_y,1) ##runif(nsims,0,1)
z <- runif(nsims,0,1)


  
hist((x*y)^z, breaks=50, freq=FALSE, xlim=c(0,1))

lines(               seq(0,1,0.01),
                     dbeta(seq(0,1,0.01),aa_x,1),
                     type="l",
                     col="purple"
)

hist(x, freq=FALSE, breaks=50, xlim=c(0,1))
lines(               seq(0,1,0.01),
                     dbeta(seq(0,1,0.01),aa_x,1),
                     type="l",
                     col="purple"
)

## compare mean, variance, and 2nd moment
prod <- (x*y)^z
mean(prod)
var(prod)
var(prod) + mean(prod)^2


mean(x)
var(x)
var(x) + mean(x)^2



```

#### alpha = 0.633

```{r, fig.show="hold", out.width="50%", echo=FALSE, results='hide'}
set.seed(1)
nsims <- 1e4
aa_x <- 0.633
aa_y <- 0.633

x <- rbeta(nsims,aa_x,1) ##runif(nsims,0,1)
y <- rbeta(nsims,aa_y,1) ##runif(nsims,0,1)
z <- runif(nsims,0,1)


  
hist((x*y)^z, breaks=50, freq=FALSE, xlim=c(0,1))

lines(               seq(0,1,0.01),
                     dbeta(seq(0,1,0.01),aa_x,1),
                     type="l",
                     col="purple"
)

hist(x, freq=FALSE, breaks=50, xlim=c(0,1))
lines(               seq(0,1,0.01),
                     dbeta(seq(0,1,0.01),aa_x,1),
                     type="l",
                     col="purple"
)

## compare mean, variance, and 2nd moment
prod <- (x*y)^z
mean(prod)
var(prod)
var(prod) + mean(prod)^2


mean(x)
var(x)
var(x) + mean(x)^2



```

### Log-scale intuition building

Consider the log scale, which changes the relation from a product raised to a power into a sum multiplied by a number.  In other words, a convolution (sum of two random variables) and a scale mixture (then multiplied by a random variable).  Take a look at this:

```{r, include=TRUE, eval=TRUE, echo=FALSE}
## okay, just keep it to beta(a,1) with a uniform 

nsims <- 1e7
aa_x <- 1
aa_y <- 1

bb_x <- 1
bb_y <- 1

x <- rbeta(nsims, aa_x, bb_x)
y <- rbeta(nsims, aa_y, bb_y)
z <- runif(nsims, 0, 1)

s.xlim <- range(c(log(x),
                  log(y),
                  z,
                  log(x*y),
                  z*log(x*y)
)
) 

s.ylim <- c(0, max(dbeta(seq(s.xlim[1],s.xlim[2],0.01), aa_x, bb_x)))

dlogbeta<-function(x,a,b) exp(a*x) * (1-exp(x))^(b-1) / beta(a,b)

par(mfcol=c(3,3))
hist(log(x), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim)
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),
               aa_x,
               bb_x),
      col="red"
)

hist(log(y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim)
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),
               aa_y,
               bb_y),
      col="red"
)

hist(    z , freq=FALSE, breaks=50, ylim=s.ylim, xlim=c(0,1))




plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(log(x)+log(y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim)
plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(z*(log(x)+log(y)), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim)
# lines(seq(s.xlim[1], s.xlim[2],0.01 ),
#       dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),
#                aa,
#                bb),
#       col="red"
# )

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")



```


  

### Sanity check: Result 2

Lets do a number of simulations and then plot the quantities to see the theory in action for $\left(\frac{1}{XY} \right)^Z  \sim$ Pareto($x_m=1$, $\alpha_m = \alpha$).  We'll plot the theoretical result in purple on top of the histogram.

```{r, fig.show="hold", out.width="50%"}
set.seed(1)
nsims <- 1e4
aa_x <- 4
aa_y <- 4

x <- rbeta(nsims,aa_x,1) ##runif(nsims,0,1)
y <- rbeta(nsims,aa_y,1) ##runif(nsims,0,1)
z <- runif(nsims,0,1)


  
hist((1/x*1/y)^z, breaks=50, freq=FALSE, xlim=c(0,10))

lines(               seq(0,10,0.01),
                     LNPar::dpareto(seq(0,10,0.01),1,alpha=aa_x),
                     type="l",
                     col="purple"
)

hist(1/x, freq=FALSE, breaks=50, xlim=c(0,10))
lines(               seq(0,10,0.01),
                     LNPar::dpareto(seq(0,10,0.01),1,alpha=aa_x),
                     type="l",
                     col="purple"
)

## compare mean, variance, and 2nd moment
prod <- (1/x*1/y)^z
mean(prod)
var(prod)
var(prod) + mean(prod)^2


mean(1/x)
var(1/x)
var(1/x) + mean(1/x)^2



```

####
####
####

## Bonus: $\alpha_x \neq \alpha_y$

  * [Wikipedia Sum of Two Independent Exponential Random Variables](https://en.wikipedia.org/wiki/Exponential_distribution#Sum_of_two_independent_exponential_random_variables)
  

There's no *one* distribution to recover since  $\alpha_x \neq \alpha_y$, so trying different distributions for $Z$ leads to different blends of  the X,Y distributions:

### $Z \sim$ U(0,1)

  * mathematica says I need incomplete gamma. luckily [vincent goulet made one for R](https://search.r-project.org/CRAN/refmans/expint/html/gammainc.html).
  * page 80 green notebook
  
### $Z \sim$ Gamma

  * page 82 green notebook
  
### $Z \sim$ Pareto  

  * TBD. don't have R code yet.  see page 81 green notebook
  
  
#### Miscellany

  *   [Proof of -ln(X) being an Exponential](https://math.stackexchange.com/a/3173387/180716)

  * [Is this transformation of beta relevant for a=0, b=1?](https://math.stackexchange.com/a/4039033/180716)
  
  * [Keep in back pocket for generalizing Uniform...U(-1,1)](https://stats.stackexchange.com/a/461337/35034)

