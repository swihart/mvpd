---
title: "(XY)^Z Part I"
author: Bruce J. Swihart
date: 2025-05-16
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include=FALSE}
library(mvpd)
```

___ 

**IN PROGRESS**

---

I'm about 8 months late to the party, but a challenge problem from 3blue1brown
caught my attention, as well as a call for intuitive approaches to explaining the result.

> Here's the challenge mode for all you math whizzes. Sample three numbers x, y, z uniformly at random in [0, 1], and compute (xy)^z. What distribution describes this result?
>
> Answer: It's uniform!
>
> I know how to prove it, but haven't yet found the "aha" style explanation where it feels expected or visualizable. If any of you have one, please send it my way and I'll strongly consider making a video on it.
>
> -- Grant Sanderson of 3blue1brown, 2024-09-10


The result and good explanations of the result have been around for a while, as shown in this [Math SE post from 2012](https://math.stackexchange.com/q/261783/180716).  

This [response video by 
Dr Mihai Nica](https://www.youtube.com/watch?v=qNXBwiAsvZM&t=277s) has an explanation that is similar to the one on this page and connects it to Poisson processes and some other statistical results.  I focus more on visualizing the distributions and thinking of the result in terms of convolution and scale mixture, which should be no surprise given these are commonly used in the underlying theory of `mvpd`.  I also generalize the result, showing that the original problem is a specific instance of the more general result.


## Restatement of the Result

For iid $X,Y \sim$ Beta($\alpha$, 1) and independent $Z \sim U(0,1)$

**Result 1**:

  * $(XY)^Z  \sim$ Beta($\alpha$, 1)
    * Which implies $Z \left( \log X + \log Y \right) \sim$ ReflectedExp($\alpha$)

**Result 2**:    

  * $\left(\frac{1}{XY} \right)^Z  \sim$ Pareto($x_m=1$, $\alpha_m = \alpha$)
    * Which implies $Z \left( \log \frac{1}{X} + \log \frac{1}{Y} \right) \sim$ Exp($\alpha$)


Special instance: For $\alpha = 1$, $X,Y,Z$ and $(XY)^Z  \sim$ U(0,1) (because Beta(1, 1) is U(0,1)).



###  Sanity check: Result 1

Lets do a number of simulations and then plot the quantities to see the theory in action for $(XY)^Z  \sim$ Beta($\alpha$, 1).  We'll plot the theoretical result in purple on top of the histogram.  First for $\alpha=1$, the special uniform instance (because that is what started it all!) and $\alpha=4.318$ as an arbitrary value bigger than 1 and $\alpha=0.633$ as an arbitrary value smaller than 1.


#### alpha = 1

```{r, fig.show="hold", out.width="50%"}
set.seed(1)
nsims <- 1e4
aa_x <- 1
aa_y <- 1

x <- rbeta(nsims,aa_x,1) ##runif(nsims,0,1)
y <- rbeta(nsims,aa_y,1) ##runif(nsims,0,1)
z <- runif(nsims,0,1)


  
hist((x*y)^z, breaks=50, freq=FALSE, xlim=c(0,1))

lines(               seq(0,1,0.01),
                     dbeta(seq(0,1,0.01),aa_x,1),
                     type="l",
                     col="purple"
)

hist(x, freq=FALSE, breaks=50, xlim=c(0,1))
lines(               seq(0,1,0.01),
                     dbeta(seq(0,1,0.01),aa_x,1),
                     type="l",
                     col="purple"
)

## compare mean, variance, and 2nd moment
prod <- (x*y)^z
mean(prod)
var(prod)
var(prod) + mean(prod)^2


mean(x)
var(x)
var(x) + mean(x)^2



```

#### alpha = 4.318

```{r, fig.show="hold", out.width="50%", echo=FALSE, results='hide'}
set.seed(1)
nsims <- 1e4
aa_x <- 4.318
aa_y <- 4.318

x <- rbeta(nsims,aa_x,1) ##runif(nsims,0,1)
y <- rbeta(nsims,aa_y,1) ##runif(nsims,0,1)
z <- runif(nsims,0,1)


  
hist((x*y)^z, breaks=50, freq=FALSE, xlim=c(0,1))

lines(               seq(0,1,0.01),
                     dbeta(seq(0,1,0.01),aa_x,1),
                     type="l",
                     col="purple"
)

hist(x, freq=FALSE, breaks=50, xlim=c(0,1))
lines(               seq(0,1,0.01),
                     dbeta(seq(0,1,0.01),aa_x,1),
                     type="l",
                     col="purple"
)

## compare mean, variance, and 2nd moment
prod <- (x*y)^z
mean(prod)
var(prod)
var(prod) + mean(prod)^2


mean(x)
var(x)
var(x) + mean(x)^2



```

#### alpha = 0.633

```{r, fig.show="hold", out.width="50%", echo=FALSE, results='hide'}
set.seed(1)
nsims <- 1e4
aa_x <- 0.633
aa_y <- 0.633

x <- rbeta(nsims,aa_x,1) ##runif(nsims,0,1)
y <- rbeta(nsims,aa_y,1) ##runif(nsims,0,1)
z <- runif(nsims,0,1)


  
hist((x*y)^z, breaks=50, freq=FALSE, xlim=c(0,1))

lines(               seq(0,1,0.01),
                     dbeta(seq(0,1,0.01),aa_x,1),
                     type="l",
                     col="purple"
)

hist(x, freq=FALSE, breaks=50, xlim=c(0,1))
lines(               seq(0,1,0.01),
                     dbeta(seq(0,1,0.01),aa_x,1),
                     type="l",
                     col="purple"
)

## compare mean, variance, and 2nd moment
prod <- (x*y)^z
mean(prod)
var(prod)
var(prod) + mean(prod)^2


mean(x)
var(x)
var(x) + mean(x)^2



```

### Log-scale for intuition building

Consider the log scale, which changes the relation from a product raised to a power into a sum multiplied by a number.  In other words, a convolution (sum of two random variables) and a scale mixture (then multiplied by a random variable).  

We will visualize this using 5 plots arranged in a 3x3 grid.  The left column will show the distributions of each of the 3 components of consideration (log(X), log(Y), and Z), the middle column will just show the convolution of log(X) and log(Y), that is to say log(X)+log(Y), and the third one will show the scale mixture applied to the convolution.

Take a look at this for alpha=1:

```{r, include=TRUE, eval=TRUE, echo=FALSE}
## okay, just keep it to beta(a,1) with a uniform 
set.seed(1)
nsims <- 1e7
aa_x <- 1
aa_y <- 1

bb_x <- 1
bb_y <- 1

x <- rbeta(nsims, aa_x, bb_x)
y <- rbeta(nsims, aa_y, bb_y)
z <- runif(nsims, 0, 1)

s.xlim <- range(c(log(x),
                  log(y),
                  z,
                  log(x*y),
                  z*log(x*y)
)
) 

s.ylim <- c(0, max(dbeta(seq(s.xlim[1],s.xlim[2],0.01), aa_x, bb_x)))

dlogbeta<-function(x,a,b) exp(a*x) * (1-exp(x))^(b-1) / beta(a,b)

par(mfcol=c(3,3), mai=c(0.3,0.3,0.3,0.3))
hist(log(x), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(X)", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),
               aa_x,
               bb_x),
      col="red"
)

hist(log(y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(Y)", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),
               aa_y,
               bb_y),
      col="red"
)

hist(    z , freq=FALSE, breaks=50, ylim=s.ylim, xlim=c(0,1), 
     main="Z", xlab="",ylab="")




plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(log(x)+log(y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(X)+log(Y)", xlab="",ylab="")
plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(z*(log(x)+log(y)), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="Z(log(X)+log(Y))", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),
               aa_x,
               bb_x),
      col="red"
)

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")



```

Quick observations --

  * log(X): is a reflected Exponential, as is log(Y)
  * log(X) + log(Y): the convolution (i.e., sum) of two reflected Exponentials is more disperse and squattier. We know this because think of adding two normals together and the variance of the resultant Normal having the sum of the variances of the original normals.
  * Z(log(X)+log(Y)): to "recover" or "get back to" the original distribution before the convolution, we need to "tighten" or "gather" or "concentrate" the distribution. Multiplying it by a random number between 0 and 1 will do exactly that. 
  
See for other values for alpha:

#### alpha = 4.318

```{r, include=TRUE, eval=TRUE, echo=FALSE}
## okay, just keep it to beta(a,1) with a uniform 
set.seed(1)
nsims <- 1e7
aa_x <- 4.318
aa_y <- 4.318

bb_x <- 1
bb_y <- 1

x <- rbeta(nsims, aa_x, bb_x)
y <- rbeta(nsims, aa_y, bb_y)
z <- runif(nsims, 0, 1)

s.xlim <- range(c(log(x),
                  log(y),
                  z,
                  log(x*y),
                  z*log(x*y)
)
) 

s.ylim <- c(0, max(dbeta(seq(s.xlim[1],s.xlim[2],0.01), aa_x, bb_x)))

dlogbeta<-function(x,a,b) exp(a*x) * (1-exp(x))^(b-1) / beta(a,b)

par(mfcol=c(3,3), mai=c(0.3,0.3,0.3,0.3))
hist(log(x), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(X)", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),
               aa_x,
               bb_x),
      col="red"
)

hist(log(y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(Y)", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),
               aa_y,
               bb_y),
      col="red"
)

hist(    z , freq=FALSE, breaks=50, ylim=s.ylim, xlim=c(0,1), 
     main="Z", xlab="",ylab="")




plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(log(x)+log(y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(X)+log(Y)", xlab="",ylab="")
plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(z*(log(x)+log(y)), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="Z(log(X)+log(Y))", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),
               aa_x,
               bb_x),
      col="red"
)

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")



```

#### alpha = 0.633

```{r, include=TRUE, eval=TRUE, echo=FALSE}
## okay, just keep it to beta(a,1) with a uniform 
set.seed(1)
nsims <- 1e7
aa_x <- 0.633
aa_y <- 0.633

bb_x <- 1
bb_y <- 1

x <- rbeta(nsims, aa_x, bb_x)
y <- rbeta(nsims, aa_y, bb_y)
z <- runif(nsims, 0, 1)

s.xlim <- range(c(log(x),
                  log(y),
                  z,
                  log(x*y),
                  z*log(x*y)
)
) 

s.xlim <- c(-5.133322,0.9999)

s.ylim <- c(0, max(dbeta(seq(s.xlim[1],s.xlim[2],0.01), aa_x, bb_x)))
s.ylim <- c(0,1.01)

dlogbeta<-function(x,a,b) exp(a*x) * (1-exp(x))^(b-1) / beta(a,b)

par(mfcol=c(3,3), mai=c(0.3,0.3,0.3,0.3))
hist(log(x), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(X)", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),
               aa_x,
               bb_x),
      col="red"
)

hist(log(y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(Y)", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),
               aa_y,
               bb_y),
      col="red"
)

hist(    z , freq=FALSE, breaks=50, ylim=s.ylim, xlim=c(0,1), 
     main="Z", xlab="",ylab="")




plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(log(x)+log(y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(X)+log(Y)", xlab="",ylab="")
plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(z*(log(x)+log(y)), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="Z(log(X)+log(Y))", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dlogbeta(seq(s.xlim[1], s.xlim[2],0.01 ),
               aa_x,
               bb_x),
      col="red"
)

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")



```


### Sanity check: Result 2

Lets do a number of simulations and then plot the quantities to see the theory in action for $\left(\frac{1}{XY} \right)^Z  \sim$ Pareto($x_m=1$, $\alpha_m = \alpha$).  We'll plot the theoretical result in purple on top of the histogram. First for $\alpha=1$, the special uniform instance (because that is what started it all for Result 1!) and $\alpha=4.318$ as an arbitrary value bigger than 1 and $\alpha=0.633$ as an arbitrary value smaller than 1.


#### alpha = 1.000

```{r, fig.show="hold", out.width="50%"}
set.seed(1)
nsims <- 1e4
aa_x <- 1
aa_y <- 1

x <- rbeta(nsims,aa_x,1) ##runif(nsims,0,1)
y <- rbeta(nsims,aa_y,1) ##runif(nsims,0,1)
z <- runif(nsims,0,1)

hist((1/x*1/y)^z, breaks=2*500, freq=FALSE, xlim=c(0,100), ylim=c(0,0.5))

lines(               seq(0,100,0.01),
                     LNPar::dpareto(seq(0,100,0.01),1,alpha=aa_x),
                     type="l",
                     col="purple"
)

hist(1/x, freq=FALSE, breaks=2*3000, xlim=c(0,100), ylim=c(0,0.5))
lines(               seq(0,100,0.01),
                     LNPar::dpareto(seq(0,100,0.01),1,alpha=aa_x),
                     type="l",
                     col="purple"
)

## compare mean, variance, and 2nd moment
prod <- (1/x*1/y)^z
mean(prod)
var(prod)
var(prod) + mean(prod)^2


mean(1/x)
var(1/x)
var(1/x) + mean(1/x)^2


```


#### alpha = 4.318

```{r, fig.show="hold", out.width="50%", echo=FALSE, results='hide'}

set.seed(1)
nsims <- 1e4
aa_x <- 4.318
aa_y <- 4.318

x <- rbeta(nsims,aa_x,1) ##runif(nsims,0,1)
y <- rbeta(nsims,aa_y,1) ##runif(nsims,0,1)
z <- runif(nsims,0,1)


  
hist((1/x*1/y)^z, breaks=30, freq=FALSE, xlim=c(0,10),ylim=c(0,3.0))

lines(               seq(0,10,0.01),
                     LNPar::dpareto(seq(0,10,0.01),1,alpha=aa_x),
                     type="l",
                     col="purple"
)

hist(1/x, freq=FALSE, breaks=50, xlim=c(0,10),ylim=c(0,3.0))
lines(               seq(0,10,0.01),
                     LNPar::dpareto(seq(0,10,0.01),1,alpha=aa_x),
                     type="l",
                     col="purple"
)

## compare mean, variance, and 2nd moment
prod <- (1/x*1/y)^z
mean(prod)
var(prod)
var(prod) + mean(prod)^2


mean(1/x)
var(1/x)
var(1/x) + mean(1/x)^2



```

#### alpha = 0.633

```{r, fig.show="hold", out.width="50%", echo=FALSE, results='hide'}

set.seed(103)
nsims <- 1e4
aa_x <- 0.633
aa_y <- 0.633

x <- rbeta(nsims,aa_x,1) ##runif(nsims,0,1)
y <- rbeta(nsims,aa_y,1) ##runif(nsims,0,1)
z <- runif(nsims,0,1)


  
hist((1/x*1/y)^z, breaks=1e6, freq=FALSE, xlim=c(0,20), ylim=c(0,0.50))

lines(               seq(0,20,0.01),
                     LNPar::dpareto(seq(0,20,0.01),1,alpha=aa_x),
                     type="l",
                     col="purple"
)

hist(1/x, freq=FALSE, breaks=1e6, xlim=c(0,20), ylim=c(0,0.50))
lines(               seq(0,20,0.01),
                     LNPar::dpareto(seq(0,20,0.01),1,alpha=aa_x),
                     type="l",
                     col="purple"
)

## compare mean, variance, and 2nd moment
prod <- (1/x*1/y)^z
mean(prod)
var(prod)
var(prod) + mean(prod)^2


mean(1/x)
var(1/x)
var(1/x) + mean(1/x)^2



```

### Log-scale for intuition building

Consider the log scale, which changes the relation from a product raised to a power into a sum multiplied by a number.  In other words, a convolution (sum of two random variables) and a scale mixture (then multiplied by a random variable).  

We will visualize this using 5 plots arranged in a 3x3 grid.  The left column will show the distributions of each of the 3 components of consideration (log(X), log(Y), and Z), the middle column will just show the convolution of log(X) and log(Y), that is to say log(X)+log(Y), and the third one will show the scale mixture applied to the convolution.

Take a look at this for alpha=1:

```{r, include=TRUE, eval=TRUE, echo=FALSE}
## sum of two indep exponentials aa_x = aa_y

nsims <- 1e7
aa_x <- 1
aa_y <- 1

bb_x <- 1
bb_y <- 1

x <- rbeta(nsims, aa_x, bb_x)
y <- rbeta(nsims, aa_y, bb_y)
z <- runif(nsims, 0, 1)


s.xlim <- range(c(log(1/x),
                  log(1/y),
                  z,
                  log(1/x * 1/y),
                  z*log(1/x*1/y)
)
) #c(-10,0)#c(-4,2)

s.ylim <- c(0, max(dbeta(seq(s.xlim[1],s.xlim[2],0.01), aa_x, bb_x)))

par(mfcol=c(3,3), mai=c(0.3,0.3,0.3,0.3))
hist(log(1/x), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(1/X)", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dexp(seq(s.xlim[1], s.xlim[2],0.01 ),
           aa_x),
      col="red"
)

hist(log(1/y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(1/Y)", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dexp(seq(s.xlim[1], s.xlim[2],0.01 ),
           aa_x),
      col="red"
)

hist(    z , freq=FALSE, breaks=50, ylim=s.ylim, xlim=c(0,1), 
     main="Z", xlab="",ylab="")




plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(log(1/x)+log(1/y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(1/X)+log(1/Y)", xlab="",ylab="")
plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(z*(log(1/x)+log(1/y)), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="Z(log(1/X)+log(1/Y))", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dexp(seq(s.xlim[1], s.xlim[2],0.01 ),
           aa_x),
      col="red"
)

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")



```

Quick observations --

  * log(X): is a reflected Exponential, as is log(Y)
  * log(X) + log(Y): the convolution (i.e., sum) of two reflected Exponentials is more disperse and squattier. We know this because think of adding two normals together and the variance of the resultant Normal having the sum of the variances of the original normals.
  * Z(log(X)+log(Y)): to "recover" or "get back to" the original distribution before the convolution, we need to "tighten" or "gather" or "concentrate" the distribution. Multiplying it by a random number between 0 and 1 will do exactly that. 
  
See for other values for alpha:

#### alpha = 4.318

```{r, include=TRUE, eval=TRUE, echo=FALSE}
set.seed(1)
nsims <- 1e3
aa_x <- 4.318
aa_y <- 4.318

bb_x <- 1
bb_y <- 1

x <- rbeta(nsims, aa_x, bb_x)
y <- rbeta(nsims, aa_y, bb_y)
z <- runif(nsims, 0, 1)


s.xlim <- range(c(log(1/x),
                  log(1/y),
                  z,
                  log(1/x * 1/y),
                  z*log(1/x*1/y)
)
) #c(-10,0)#c(-4,2)

s.ylim <- c(0, max(dbeta(seq(s.xlim[1],s.xlim[2],0.01), aa_x, bb_x)))

par(mfcol=c(3,3), mai=c(0.3,0.3,0.3,0.3))
hist(log(1/x), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(1/X)", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dexp(seq(s.xlim[1], s.xlim[2],0.01 ),
           aa_x),
      col="red"
)

hist(log(1/y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(1/Y)", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dexp(seq(s.xlim[1], s.xlim[2],0.01 ),
           aa_x),
      col="red"
)

hist(    z , freq=FALSE, breaks=50, ylim=s.ylim, xlim=c(0,1), 
     main="Z", xlab="",ylab="")




plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(log(1/x)+log(1/y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(1/X)+log(1/Y)", xlab="",ylab="")
plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(z*(log(1/x)+log(1/y)), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="Z(log(1/X)+log(1/Y))", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dexp(seq(s.xlim[1], s.xlim[2],0.01 ),
           aa_x),
      col="red"
)

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")



```

#### alpha = 0.633

```{r, include=TRUE, eval=TRUE, echo=FALSE}
set.seed(1)
nsims <- 1e4
aa_x <- 0.633
aa_y <- 0.633

bb_x <- 1
bb_y <- 1

x <- rbeta(nsims, aa_x, bb_x)
y <- rbeta(nsims, aa_y, bb_y)
z <- runif(nsims, 0, 1)


s.xlim <- range(c(log(1/x),
                  log(1/y),
                  z,
                  log(1/x * 1/y),
                  z*log(1/x*1/y)
)
) #c(-10,0)#c(-4,2)

s.ylim <- c(0,1.1)

par(mfcol=c(3,3), mai=c(0.3,0.3,0.3,0.3))
hist(log(1/x), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(1/X)", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dexp(seq(s.xlim[1], s.xlim[2],0.01 ),
           aa_x),
      col="red"
)

hist(log(1/y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(1/Y)", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dexp(seq(s.xlim[1], s.xlim[2],0.01 ),
           aa_x),
      col="red"
)

hist(    z , freq=FALSE, breaks=50, ylim=s.ylim, xlim=c(0,1), 
     main="Z", xlab="",ylab="")




plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(log(1/x)+log(1/y), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="log(1/X)+log(1/Y)", xlab="",ylab="")
plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")
hist(z*(log(1/x)+log(1/y)), freq=FALSE, breaks=50, ylim=s.ylim, xlim=s.xlim, 
     main="Z(log(1/X)+log(1/Y))", xlab="",ylab="")
lines(seq(s.xlim[1], s.xlim[2],0.01 ),
      dexp(seq(s.xlim[1], s.xlim[2],0.01 ),
           aa_x),
      col="red"
)

plot(NA,NA,axes=F,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="")



```

So far we have considered cases where the alpha for X and Y are the same and how multiplying (log(X)+log(Y)) by Z allows one to recover the original distribution of log(X) (equivalently, log(Y)).  However, if $\alpha_x \neq \alpha_y$, multiplying by a uniform would not recover either distribution, it would be a distribution "in-between" those two distributions.  We consider this as bonus case below.


## Bonus: $\alpha_x \neq \alpha_y$

Firstly, one may want to consult wikipedia.

  * [Wikipedia Sum of Two Independent Exponential Random Variables](https://en.wikipedia.org/wiki/Exponential_distribution#Sum_of_two_independent_exponential_random_variables)
  

There's no *one* distribution to recover since  $\alpha_x \neq \alpha_y$, so trying different distributions for $Z$ leads to different blends of  the X,Y distributions:

### $Z \sim$ U(0,1)

  * mathematica says I need incomplete gamma. luckily [vincent goulet made one for R](https://search.r-project.org/CRAN/refmans/expint/html/gammainc.html).
  * page 80 green notebook
  
### $Z \sim$ Gamma

  * page 82 green notebook
  
### $Z \sim$ Pareto  

  * TBD. don't have R code yet.  see page 81 green notebook
  
  
#### Miscellany

  *   [Proof of -ln(X) being an Exponential](https://math.stackexchange.com/a/3173387/180716)

  * [Is this transformation of beta relevant for a=0, b=1?](https://math.stackexchange.com/a/4039033/180716)
  
  * [Keep in back pocket for generalizing Uniform...U(-1,1)](https://stats.stackexchange.com/a/461337/35034)

